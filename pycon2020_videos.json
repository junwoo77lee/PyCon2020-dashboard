{
    "sponsor-workshops": [
        {
            "Author": "Charles Engelke",
            "Bio": "Charles Engelke works in developer relations for Google Cloud Platform, and previously had a variety of roles at a mid-sized software firm, culminating in Chief Technology Officer and Vice President. Before entering industry he taught university classes in math and computer science. He has presented at several conferences, both small industry focused ones as well as larger public ones.",
            "Title": "Google: Building Serverless Python Applications with Google Cloud",
            "Description": "You know how to program in Python. Now learn how to apply that skill to building distributed serverless applications in the cloud. You won’t write just one program, you’ll create several and connect them through a shared database, network requests, message queues, or triggering events. This is a hands-on workshop–bring your own PC and leave having built and deployed a significant cloud application. You’ll see not only how to use different cloud services to run your code, but why you would choose each one for an application’s specific needs. The workshop uses Google Cloud Platform services, including Cloud Functions, Cloud Run, App Engine, Firestore, PubSub, and Identity-Aware Proxy, but the concepts covered can be applied to any major cloud platform.",
            "Video_link": "https://www.youtube.com/watch?v=4bjX9iKqpXA",
            "Video_id": "4bjX9iKqpXA",
            "viewCount": 980,
            "likeCount": 17,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Louise Grandjonc",
            "Bio": "Hi, I’m Louise, I am a software developer working at citus data (now Microsoft). I have been a python/django developer for 6 years, and I just love it, that and postgreSQL. I am always curious about learning SQL and enjoy working on performance! I am involved in the postgres community as well, as a speaker and also a member of postgresWomen, a group to promote diversity in the world of databases.",
            "Title": "Microsoft: Optimize Python & Django apps with easy-to-learn Postgres Superpowers",
            "Description": "Building Django applications that perform well and can scale is a challenge all of us developers have. And yet getting performance right is essential to your business and to your work as a developer. In this workshop, we will teach you a few key Postgres superpowers that will enable you to optimize your Python and Django apps. \nJust like chocolate and peanut butter go better together, so do Python and Postgres. So we’ll use Azure Database for PostgreSQL as the underlying database for this workshop. \nThrough interactive exercises, we will walk through what to do in the face of the most common of common pain points: slow queries. We’ll teach you what to look out for, and we’ll do an ORM deep dive into application code to identify performance bottlenecks. Together, we’ll analyze both Python code samples as well as example SQL code. And we’ll explore the power of Azure performance insights, which can be used as a multiplying factor when it comes to performance optimization. Finally, we’ll explain how to scale out your underlying Postgres database horizontally using Hyperscale (Citus), in a way that is transparent to your application and does not require any re-architecture on your part.",
            "Video_link": "https://www.youtube.com/watch?v=dyBLGjCQJHs&feature=youtu.be",
            "Video_id": "dyBLGjCQJHs",
            "viewCount": 715,
            "likeCount": 26,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Tania Allard",
            "Bio": "Tania is a Sr. Developer Advocate at Microsoft with vast experience in academic research and industrial environments. Her main areas of expertise are within data-intensive applications, scientific computing, and machine learning. She has conducted extensive work on the improvement of processes, reproducibility and transparency in research, data science and artificial intelligence.\nShe is passionate about mentoring, open source, and its community and is involved in several initiatives aimed to build more diverse and inclusive communities. She is also a contributor, maintainer, and developer of a few open source projects and the Founder of Pyladies NorthWest UK.",
            "Title": "Microsoft: Easy Data Processing on Azure with Serverless Functions",
            "Description": "Serverless computing (also known as function as a service, FaaS) is a design pattern where applications are hosted by a third-party service (i.e. Azure) eliminating the need for server software and hardware management by the developer. \nServerless can be an excellent alternative for Pythonistas interested in data processing as it allows them to focus on their code rather than the cloud infrastructure. This workshop will introduce attendees to Azure Functions for data processing scenarios (including data acquisition, cleaning and transformation and storage for subsequent usage).\nAfter this tutorial, attendees will have had practical experience with Azure functions for data processing scenarios. Also, they will leave the workshop with a basic function for data processing that could be further modified/extended to suit their needs/requirements.\nOutline\n1.  Introduction\na.   Setup and install troubleshooting \nb.  Introduction to serverless and Azure functions - why serverless can be an excellent alternative for data processing scenarios\n2.  Creating your first Azure function\na.  Creating a simple scheduled function - 101 azure function for Python developers\nb.  Using the VS Code extension - simplify your workflow with the VS Code extension and start with a solid base\nc.  Understanding triggers and bindings - how to schedule tasks with the “timer” trigger \nd.  Deploying to Azure - using the VS code extension and familiarising with the Azure portal\n3.   Data processing with serverless\na.  Updating your scheduled function to collect data from third-parties APIs\nb.   Data cleaning, aggregation and storage - going from raw data to usable, clean data that can be readily accessed by your team members\n4.  Improving your Azure function experience - optional\na.  CI / CD for Azure functions - using GitHub actions to deploy your functions automatically\nb.  Azure functions for reporting - integrate with Slack or Teams\nc.  Monitoring and troubleshooting functions\n  Pre-requisites\nThis workshop is aimed at folks interested in data processing, data engineering or data science. The goal is to provide a practical introduction to serverless for data processing scenarios.\nWe assume that attendees:\n- Have intermediate Python knowledge\n- Have some experience with data wrangling and/or data processing (not extensive experience required but have, for example, used libraries like pandas and requests for data wrangling and API access)\n- Are comfortable using the command line/terminal (no need to be an expert but should be comfortable enough to navigate file systems and perform necessary Git tasks)\nSoftware related:\nA detailed guide of the workshop setup/install instructions will be sent before the workshop.",
            "Video_link": "https://youtu.be/PV7iy6FPjAY",
            "Video_id": "PV7iy6FPjAY",
            "viewCount": 278,
            "likeCount": 5,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Mark Ibrahim",
            "Bio": "Mark is a research engineer at Facebook AI Research exploring techniques for secure machine learning. Previously, he led a team researching interpretability methods for explaining neural network models at Capital One’s Center for Machine Learning. Mark also worked on various engineering projects from a real-time notification system for predicting unusual charges to a graph search engine powered by Wikipedia. He enjoys good coffee, math, and editing text in Vim!",
            "Title": "Facebook: Machine Learning on Encrypted Data with CrypTen",
            "Description": "CrypTen is a machine learning framework built on PyTorch that enables you to easily study and develop machine learning models using secure computing techniques. CrypTen allows you to develop models with the PyTorch API while performing computations on encrypted data – without revealing the protected information. Different parties can contribute information to the model or measurement without revealing what they contributed.\nIn this workshop, we will teach participants how to use CrypTen using interactive notebooks - participants should bring a laptop with Jupyter notebook installed. We will work through four common use scenarios for privacy preserving machine learning using secure multiparty computation to allow learning without sharing data:\n- Feature Aggregation: multiple parties hold distinct sets of features, and want to perform computations over the joint feature set. \n- Data Labeling: one party holds feature data while another party holds corresponding labels, and they would like to learn a relationship between the features and labels. \n- Dataset Augmentation: several parties each hold a small number of observations, and would like to use all the observations in order to improve the statistical power of a measurement or model. \n- Model Hiding: one party has access to a trained model, while another party would like to apply that model to its own data. \nWhat we’ll cover: \n- Installation / Setup (20 min)\n- Machine Learning and CrypTen (10 min)\n- Secure Multiparty Compute and Tensors in CrypTen (15 min)\n- Training a Machine Learning Model on Encrypted Data (45 min)",
            "Video_link": "https://youtu.be/CLunSEdSDaA",
            "Video_id": "CLunSEdSDaA",
            "viewCount": 163,
            "likeCount": 2,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Steven Lott",
            "Bio": "Steven Lott is a Lead Engineer at Capital One, where he helps with the enterprise cloud initiatives including products like Cloud Custodian. He’s been building software from the ancient times when computers were large, expensive, and rare. He’s the author of a number of books on Python, available from Packt Publishing. While some of this material is drawn in part from Functional Python Programming, 2nd edition, other parts are unique to PyCon 2020.",
            "Title": "Capital One: Type Hints: Putting more Buzz in your Fizz",
            "Description": "Since PEP 484 in 2014, type hints and the mypy tool have become an important part of the Python ecosystem. Type hints provide an incremental way to add information to the Python source, which can be checked by external tools like mypy and some IDE environments like PyCharm. Type hint checking can be part of a CI/CD pipeline to provide confidence that the code is likely to behave properly at run-time. Python’s Duck-Typing approach can lead to working code that is hard to describe with available type hints. \nThis tutorial expects hands-on participation with a large number of small examples. It will start with some simple cases of type hints. We’ll look at complex data structures and ways to factor the complexity out of the type hints. We’ll look at circular type references, common on problems where graphs are represented. The techniques for “debugging” type hints will focus on exposing the mypy reasons about the source code. \nWe’ll look at two very easy and useful ways to incorporate type hints into class definitions using the typing.NamedTuple class and the @dataclass decorator. We’ll also look at situations where the type: ignore comment can be appropriate. Another important topic will touch on how we can write a stub for a library where the code doesn’t have type hints.",
            "Video_link": "https://youtu.be/udVRTBm_-q0",
            "Video_id": "udVRTBm_-q0",
            "viewCount": 303,
            "likeCount": 11,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Casey Faist",
            "Bio": "Casey is the Queen Pythonista at Heroku, the leading Python platform-as-a-service that powers millions of apps.\nShe’s the former director of Florida PyCon, who’s done everything from neuroscience experiments on humans to worked as a farmhand.\nAsk her about feathery dinosaurs, FIRE, or about her favorite hobby: making terrible puns while walking around in Ikea.",
            "Title": "Heroku: From Project to Productionized on Heroku",
            "Description": "In this workshop, we will take a Django application from development to ready for deployment on Heroku. We’ll talk about 12 Factor Django apps and why you’d want one, then work through the configuration updates you’ll need to make your application robust and Heroku ready. We’ll take a quick tour of your Heroku Dashboard. We’ll add some human complexity and talk about how to collaborate with others and how to control and share access on Heroku, and then some debugging tips along the way. You’ll leave with everything you need to hit the ground running with Django on Heroku.",
            "Video_link": "https://youtu.be/1923eduj0Gg",
            "Video_id": "1923eduj0Gg",
            "viewCount": 225,
            "likeCount": 7,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Patrick Lysaght",
            "Bio": "",
            "Title": "Xilinx: Extending the Python Ecosystem to Xilinx Programmable Platforms with PYNQ",
            "Description": "Imagine if we could combine the beneﬁts of Raspberry PI microprocessors, Arduino microcontrollers and the programmable logic of a ﬁeld programmable gate array (FPGA) in a single development platform? What if we could connect all of these components together with high speed interconnect and add lots of programmable, high-speed IO? That would be quite the embedded development dream machine! Things would be even more exciting if we could integrate all of the parts into a single programmable system-on-chip. \nBut wait … hardware, without good software, is just scrap metal! We need to program the machine with a user-friendly programming language with hundreds of thousands of libraries, so that we would not have to re-write code for problems that we know have already been solved. And since this is a wish-list for our dream machine, we should make sure to include libraries for machine learning and data science because these are some of the hottest areas that we want to explore.\nThis workshop will introduce PYNQ, based on Xilinx programmable System-on-Chips. PYNQ serves up a browser-based, integrated development environment (IDE) for Python, so that new users can experience the power of Xilinx platforms without having to install new software, or create their own FPGA hardware designs. Meanwhile, PYNQ makes experienced developers more productive and helps them to create, document, and distribute their designs, more eﬀectively.",
            "Video_link": "https://youtu.be/ooOLl4_H-IE",
            "Video_id": "ooOLl4_H-IE",
            "viewCount": 522,
            "likeCount": 22,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Keith Kraus, Bartley Richardson",
            "Bio": "Keith Kraus is a Manager in the AI Infrastructure team at NVIDIA in the greater New York City area. Keith is a core developer on RAPIDS and works extensively on the Python interface, API design, distributed computation architecture, and big data integration. Prior to working for NVIDIA, Keith worked in cybersecurity and focused on building a GPU-accelerated big data solution for advanced threat detection. Keith holds an MEng in networked information systems from Stevens Institute of Technology.",
            "Title": "NVIDIA: GPU-Accelerated Data Analytics in Python",
            "Description": "As data volumes and computational complexity of data analysis techniques have increased, so has the need for acceleration of these workloads to allow the data scientist to quickly iterate on models. One of the key ways to achieve this has been through GPU acceleration. Traditionally, GPU acceleration has required specialized knowledge of low-level C++ GPGPU programming. However, the open-source RAPIDS data science libraries allow data scientists to easily make use of GPU acceleration in common ETL, machine learning, and graph analytics workloads using familiar Python APIs (e.g. pandas and scikit-learn).\nThis workshop will introduce RAPIDS, walk through its component libraries, and will show participants how these libraries allow them to easily introduce GPU acceleration into their workflows to speed up compute times and increase iteration on their models. We will demonstrate common data ETL (cuDF), machine learning (cuML), graph analytics (cuGraph), signal processing (cuSignal), spatial analytics (cuSpatial), and InfoSec (cyber log accelerator) workloads that RAPIDS accelerates. We will also discuss how users can integrate RAPIDS and the broader open-source GPU data science ecosystem to solve their specific use cases.\nAn understanding of basic data science concepts will be helpful, but is not required. No experience with GPU programming is required!",
            "Video_link": "https://youtu.be/AxDJWkRISL8",
            "Video_id": "AxDJWkRISL8",
            "viewCount": 124,
            "likeCount": 2,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Jason Lantz",
            "Bio": "",
            "Title": "Salesforce: How Python Powers Salesforce.org's Unique Open Source Model",
            "Description": "Salesforce.org’s core products are the most installed open source packages run on top of Salesforce’s enterprise platform. The processes and open source tools we’ve built using Python to streamline and scale our internal development of those packages are also used by our community to build shared solutions on top of our products. Inspired by our community’s desire to share, we created the Salesforce.org Open Source Commons, a program that incubates and fosters sustainable, community run open source projects for the nonprofit and education sectors.\nIn this workshop, we’ll show how the open source tooling we built using Python and some of the best open source projects from the Python ecosystem have helped us get closer to our vision of fostering open source collaboration beyond just developers. You’ll learn how you can apply your knowledge of Python to better understand the Salesforce platform and build Salesforce integration into your own Python web apps. With this knowledge, you’ll be empowered to volunteer with the 30k+ nonprofit and education organizations already using Salesforce and learn how Python application developers can easily build repeatable, scalable Salesforce solutions to integrate your Python applications with the most popular enterprise CRM in the world.",
            "Video_link": "https://youtu.be/XL77lRTVF3g",
            "Video_id": "XL77lRTVF3g",
            "viewCount": 200,
            "favoriteCount": 0,
            "commentCount": 0
        }
    ],
    "talks": [
        {
            "Author": "Jeff Bass",
            "Bio": "Jeff studied econometrics in graduate school, then spent a 30 year career writing code in statistics, economics, and biotech. Now writing computer vision software in Python to enable small Raspberry Pi computers to track wildlife and manage his small urban permaculture farm in Southern California. Author / maintainer of imagezmq, a set of Python classes for moving OpenCV images between computers using the ZMQ messaging library. Also an avid touring cyclist.",
            "Title": "Yin Yang Ranch: Building a Distributed Computer Vision Pipeline using Python, OpenCV and ZMQ",
            "Description": "I am building a small permaculture farm in Southern California. I have written computer vision programs in Python to read the water meter, optimize water use, track coyotes, rabbits, raccoons and bobcats, etc. The farm is set up like an ongoing science project. I am running Python on 20 Raspberry Pi computers with PiCameras and sensors. The RPi’s capture images, detect motion and select a subset of images. Did the water meter move? Was a coyote seen? If so, images are sent to a hub computer via PyZMQ. The hub computer uses Python and OpenCV to do more advanced processing like reading the water meter digits or keeping critter counts by season. This arrangement demonstrates ways that Python can be helpful in developing IOT networks with multiple cameras and sensors.\nIn this talk I will describe the hub and spoke design that distributes processing across a mix of RPi’s and larger computers. I’ll cover the pros and cons of PyZMQ messaging for image transfer. I’ll describe OpenCV techniques in Python that have been helpful on both the RPi’s and the hub computer. All the programs are pure Python, and they leverage fast libraries written in C, like OpenCV and ZMQ by using Python bindings.  This is an open source project with all the Python source code available on GitHub. Hardware “how to’s” & photos are also on GitHub. Pictures of my farm and my favorite coyotes are also on GitHub…because why not?",
            "Video_link": "https://youtu.be/76GGZGneJZ4",
            "Video_id": "76GGZGneJZ4",
            "viewCount": 1201,
            "likeCount": 46,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 14
        },
        {
            "Author": "Jonathan Crall",
            "Bio": "Jon Crall is a computer vision researcher and Python enthusiast. He enjoys quality software, simple setups, and probabilistic guarantees. He has a B.S. from SUNY-IT and a Ph.D. from RPI, both in computer science. He works at Kitware as a Senior R&D Engineer. He is the primary author of several Python modules including ubelt, xdoctest, netharn, and ibeis and actively makes contributions to open-source software when possible. He hopes that software can improve the welfare of others, and he wants to make it easier to write better software.",
            "Title": "Developing With Doctests",
            "Description": "This talk is about doctests — a way to embed examples and unit tests in docstrings. I describe what they are, how to write them, and interesting ways in which they can be used. Doctests make it easy to interactively develop code by defining “demo” inputs which can be copied into IPython. The side effect is a unit test. This is test-driven-development at its best. I explain the technical details of doctest syntax, directives, parsing, and execution.\nUnfortunately, Python’s builtin doctest module has a restrictive syntax, which makes it difficult to use. In the second part of the talk I introduce an alternative: Xdoctest, a new, but stable package for parsing and running doctests (with optional pytest integration). I explain why doctest’s regex-based parser is fundamentally limited and how xdoctest’s ast-based parser is the remedy. I demonstrate how to use xdoctest and discuss its advantages and disadvantages. By the end of this talk you feel confident in writing, running, and developing with doctests.",
            "Video_link": "https://youtu.be/CUjCqOw_oFk",
            "Video_id": "CUjCqOw_oFk",
            "viewCount": 1049,
            "likeCount": 47,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 10
        },
        {
            "Author": "Jessica Garson",
            "Bio": "Jessica Garson is a Python programmer, educator, and artist. She currently works at Twitter as a Developer Advocate. In her spare time, she is on a never-ending quest for the perfect vegan snack.",
            "Title": "How I Solved my NYC Parking Problem with Python",
            "Description": "Since I have a car in New York City, my car is subject to the city’s alternate side of the street parking regulations. This means most nights I need to move my car before the early morning street cleaning that happens in my neighborhood. I had developed a nightly routine around moving my car before I go to sleep. I am sometimes a bit too good at this and I often move my car on days I don’t need to. Since alternate side of the street parking is often canceled on days where there are holidays, or bad weather, there is a Twitter handle @NYCASP, which posts daily and whenever there is an emergency situation. I used Python, Twilio and the Twitter API to solve this problem for myself so I get a text message whenever I don’t need to move my car.",
            "Video_link": "https://youtu.be/bK2iPDu7RDE",
            "Video_id": "bK2iPDu7RDE",
            "viewCount": 1585,
            "likeCount": 53,
            "dislikeCount": 3,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Trey Hunner",
            "Bio": "Trey Hunner helps Python professionals level-up their skills through Python Morsels, a service for hands-on weekly Python learning.\nTrey also helps software teams turn their turn professional developers into professional Python developers through on-site Python trainings.",
            "Title": "Comprehensible Comprehensions",
            "Description": "Finding list comprehensions incomprehensible?  Having trouble figuring out when to use list comprehensions or just plain for loops? Are your coworkers overusing comprehensions?\nCome to this talk and learn the how, when, and why of list comprehensions.\nWe’ll discuss:\nComprehensions are a unique tool for a unique task. Even if you dislike them, understanding how they work will help you better understand the Python code you find in the wild.\nYou’ll leave this talk with a better appreciation for both the use cases for comprehensions in Python and an understand of when not to use them.",
            "Video_link": "https://youtu.be/ei71YpmfRX4",
            "Video_id": "ei71YpmfRX4",
            "viewCount": 2515,
            "likeCount": 112,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 6
        },
        {
            "Author": "Russell Keith-Magee",
            "Bio": "Dr Russell Keith-Magee is the founder of the BeeWare project, developing GUI tools and libraries to support the development of Python software on desktop and mobile platforms. He is also a 14 year veteran of the Django core team, and for 5 years, was President of the Django Software Foundation. In his day job, he wrangles data pipelines for Survata.",
            "Title": "Snakes in a case: Packaging Python apps for distribution",
            "Description": "So you’ve written a Python program - a game, a new social media app, or a system administration utility. You think it’s great, and you want to share it with the world. But how do you do that? How do you distribute your code to others without needing to document how to set up Python, install dependencies, and run your application?\nIn this talk, you’ll learn about Briefcase, a tool that can convert a Python project into platform-native installers on macOS, Windows and Linux - and can also target iOS and Android. You’ll learn how to use Briefcase to start a new project, or convert an existing project for distribution. You’ll also see how Briefcase (and some other recent developments in the Python ecosystem) can assist you during application development.",
            "Video_link": "https://youtu.be/WjMDXDHBn1I",
            "Video_id": "WjMDXDHBn1I",
            "viewCount": 2026,
            "likeCount": 84,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Andrew Knight",
            "Bio": "Pandy Knight is the “Automation Panda” - a Pythoneer, consultant, and international speaker who loves all things about software. He specializes in building robust test automation solutions that run hundreds of tests continuously. Andy currently works full-time as the lead software engineer in test at PrecisionLender, but he also teaches part-time as an adjunct professor at Wake Technical Community College. Read his tech blog at AutomationPanda.com, and follow him on Twitter at @AutomationPanda.",
            "Title": "East Meets West When Translating Django Apps",
            "Description": "你好！我是软件工程师。\nPlease, someone translate! Thankfully, it’s easy to do in Django for both new apps and existing ones. We’ll cover language detection, URL routing, translation files, and marking strings to translate (particularly overlooked areas). As a bonus, we’ll also look at translating the Django admin site! We’ll use Mandarin for examples, but the techniques will work for any language.",
            "Video_link": "https://youtu.be/OUkzFbzkXy4",
            "Video_id": "OUkzFbzkXy4",
            "viewCount": 515,
            "likeCount": 21,
            "dislikeCount": 2,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Katie McLaughlin",
            "Bio": "Katie has worn many different hats over the years. She’s currently a Cloud Developer Advocate at Google, Director of the Python Software Foundation, Django Software Foundation, and Conference Director for PyCon AU 2018/2019. When she’s not changing the world, she enjoys making tapestries, cooking, and seeing just how well various application stacks handle emoji.",
            "Title": "What is deployment, anyway?",
            "Description": "So you’ve finished the DjangoGirls tutorial, but now you want to share it with the outside world, but how do you go about that?\nWhat even is production? What is the deal with web servers versus web service gateway interfaces? And static, what’s that, then? What is involved in choosing a platform or infrastructure as a service? What even are databases? \nIn this presentation, we will discuss the basics beyond running a Django project locally, and discuss the concepts and strategies around how to deploy your project, ultimately answering the question, “What is deployment, anyway?”",
            "Video_link": "https://youtu.be/8vstov3Y7uE",
            "Video_id": "8vstov3Y7uE",
            "viewCount": 1916,
            "likeCount": 64,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Marlene Mhangami",
            "Bio": "Marlene Mhangami is a PSF Director and the co-founder of ZimboPy, a Zimbabwean non-profit that empowers women to pursue careers in tech. Marlene is also the current chair of Pycon Africa, the first pan-African gathering of the Python community. She currently lives in Harare and has played an active role in assisting the growth of Python communities both locally and across the continent for the past three years.",
            "Title": "Leadership and Identity in the Pan-African Python movement",
            "Description": "In this talk, I will be outlining some of the unique aspects of being a young, female community leader in the budding Pan-African Python movement. I will begin by giving the audience an overview of the current state of the African Python community and my role in its development. I will then share some of my personal experiences, both positive and negative, leading in community spaces and juxtapose them to some philosophical ideas about leadership. I will be sharing some of my favorite philosophers’ ideas on the topic, as well as some perspectives on how online communities have historically treated leadership. All of this information will be used, to make a proposition for how our community should view and identify leaders. I also go on to share how my personal and group identity as an African has played a large role in shaping how I lead. Our unique identities are incredibly significant, I argue that Pythonistas intending to build a more diverse and inclusive global community should be thoughtful about their identity. Finally, I will be sharing some anecdotes on what I believe the future leaders of our community should look like.",
            "Video_link": "https://youtu.be/PQmCADPolOE",
            "Video_id": "PQmCADPolOE",
            "viewCount": 508,
            "likeCount": 28,
            "dislikeCount": 3,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Carol Smith",
            "Bio": "Carol Smith has been leading research to improve the human experience in AI systems since 2015, including work on autonomous vehicles. Her user experience (UX) career spans nearly 20 years collaborating on complex problems and working across industries and platforms. She is currently a Senior Research Scientist in Human-Machine Interaction at Carnegie Mellon University’s SEI. Carol is recognized globally as a leader in UX, has served two terms on the UXPA international board, and holds an M.S. in Human-Computer Interaction from DePaul University. Carol lives in Pittsburgh and enjoys outdoor activities with her family, running and playing soccer.",
            "Title": "Implementing Ethics: Developing Trustworthy AI",
            "Description": "Ethics discussions abound, but translating “do no harm” into our work is frustrating at best, and obfuscatory at worst. We can agree that keeping humans safe and in control is important, but implementing ethics is intimidating work.\nLearn how to wield your preferred technology ethics code to make an AI system that is accountable, de-risked, respectful, secure, honest and usable. The presenter will introduce the topic of ethics and then step through a user experience (UX) framework to guide AI development teams successfully through this process.",
            "Video_link": "https://youtu.be/vPokIvli8yk",
            "Video_id": "vPokIvli8yk",
            "viewCount": 406,
            "likeCount": 13,
            "dislikeCount": 4,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Takanori Suzuki",
            "Bio": "Takanori is a Vice-chair of PyCon JP Committee(www.pycon.jp). He is also a director of BeProud Inc.(www.beproud.jp), and his title is “Python Climber”. He held PyCon JP 2014 to 2016 as the chairperson. Currently he teaches Python to beginners as a lecturer at Python Boot Camp(pycamp.pycon.jp) all over Japan. In addition, he published several Python books.\nSince 2019 he has started to present at international Python conferences around the world(APAC, US, TH, Euro, MY, JP, TW, SG and ID).\nHe plays trumpet, climbs boulder, loves Lego, ferrets and beer.",
            "Title": "Automate the Boring Stuff with Slackbot",
            "Description": "Today, there are many tasks to repeat in the company/community.\nIn addition, we often use chat such as Slack for daily communication.\nSo, I created a chatbot(PyCon JP Bot) to automate various boring tasks related to holding PyCon JP.\nIn this talk, I will first explain how to create a chatbot using slackbot.\nI will tell you how to registers bot’s integration on Slack and how to create a simple bot in Python that responds to specific keywords.\nAnd as a specific case, I will explain how to make a bot command to perform the following operations and technical problems.\n- Emoji reaction\n- Block-kit\n- Calculator: SymPy\n- Karma(plusplus): Peewee\n- Search issues, display issue details: JIRA API\n- Create multiple issues from a template: JIRA API, Sheets Spreadsheet API\n- Search files from Google Drive: Google Drive API\n- Account management of G Suite(user, alias, group and member): G Suite API\n- etc.",
            "Video_link": "https://youtu.be/ndi55Ig6-SI",
            "Video_id": "ndi55Ig6-SI",
            "viewCount": 1599,
            "likeCount": 36,
            "dislikeCount": 2,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Itamar Turner-Trauring",
            "Bio": "Itamar helps programmers and data scientists using Python ship features faster, with training and consulting. He has been using Python since 1999, and worked on scientific computing, distributed systems, and more. His open source work includes the Eliot logging library (https://eliot.readthedocs.io) and in the past he was a contributed to Twisted. You can learn more about software engineering skills for data scientists, Docker packaging for Python, and more at https://pythonspeed.com.",
            "Title": "Small Big Data: using NumPy and Pandas when your data doesn't fit in memory",
            "Description": "Your data is too big to fit in memory—loading it crashes your program—but it’s also too small for a complex Big Data cluster. How to process your data simply and quickly?\nIn this talk you’ll learn the basic techniques for dealing with Small Big Data: money, compression, batching, and indexing. You’ll specifically learn how to apply these techniques to NumPy and Pandas, but you’ll also learn the key concepts you can apply to other libraries and the specifics of your particular data.",
            "Video_link": "https://youtu.be/8pFnrr0NnwY",
            "Video_id": "8pFnrr0NnwY",
            "viewCount": 1352,
            "likeCount": 47,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Dean Wampler",
            "Bio": "Dean Wampler works at Anyscale, focusing on Ray, which is used to build distributed applications such as Python-based ML/AI applications. Previously, he led the development of Lightbend CloudFlow, a system for building and running streaming data applications with tools like Apache Spark and Kafka. Dean is the author of several books, an open-source contributor, and a frequent conference speaker and co-organizer. Dean has a Ph.D. in Physics from the University of Washington.",
            "Title": "Ray: A System for High-performance, Distributed Python Applications",
            "Description": "Ray is an open-source, distributed framework from U.C. Berkeley’s RISELab that easily scales Python applications from a laptop to a cluster, with an emphasis on the unique performance challenges of ML/AI systems. It is now used in many production deployments. \nI’ll explain the problems that Ray solves and useful features it provides, such as rapid distribution, scheduling, and execution of “tasks” and management of distributed stateful “serverless” computing. I’ll illustrate how it’s used in several ML libraries. You’ll learn when to use Ray and how to use it in your projects.",
            "Video_link": "https://youtu.be/tqUe0gcfqAU",
            "Video_id": "tqUe0gcfqAU",
            "viewCount": 1135,
            "likeCount": 29,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Conor Hoekstra",
            "Bio": "Conor is a Senior Library Software Engineer at NVIDIA working on the RAPIDS team. He has 6 years of professional C experience, 1 year or professional Python experience and is on the ISO C Canadian National Body. He is extremely passionate about programming languages, algorithms and beautiful code. He has a YouTube channel where he covers solutions to competitive programming problems using various programming languages and algorithms.\nTwitter: https://twitter.com/code_report\nYouTube: https://www.youtube.com/codereport\nGithub: https://github.com/codereport\nLinkedIn: https://www.linkedin.com/in/conorhoekstra/",
            "Title": "Beautiful Python Refactoring",
            "Description": "Refactoring can lead to absolutely beautiful code. Not only this, but the refactoring itself can be a thing of beauty. This talk demonstrates taking an example with a double-digit number of lines of code down to a single-digit number of lines of code. This talk will show how to identify certain anti-patterns that can be replaced with more expressive and declarative code. This is a simple talk that can be understood by all, but when applied to one’s daily work can make a significant difference.",
            "Video_link": "https://youtu.be/W-lZttZhsUY",
            "Video_id": "W-lZttZhsUY",
            "viewCount": 4394,
            "likeCount": 189,
            "dislikeCount": 7,
            "favoriteCount": 0,
            "commentCount": 22
        },
        {
            "Author": "Dustin Ingram",
            "Bio": "Dustin is a Developer Advocate at Google, focused on supporting the Python community on Google Cloud. He’s also a member of the Python Packaging Authority, maintainer of PyPI, organizer for the PyTexas conference.",
            "Title": "Static Typing in Python",
            "Description": "Python is well-known as a programming language without static types. This means that you don’t need to say what a given variable will hold, or whether your function will return a string or an integer (or sometimes one, and sometimes another!). This has historically made Python a very flexible and beginner-friendly language.\nIn this talk, we’ll discuss the advantages and disadvantages to a static type system, as well as recent efforts to introduce static typing to Python via optional “type hints” and various tools to aid in adding types to Python code. We’ll see what this means for Python, for Python programmers, and what the future has in store for Python’s type system.",
            "Video_link": "https://youtu.be/ST33zDM9vOE",
            "Video_id": "ST33zDM9vOE",
            "viewCount": 2637,
            "likeCount": 172,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 15
        },
        {
            "Author": "Mason Egger",
            "Bio": "Mason is currently a Developer Advocate at DigitalOcean who specializes in cloud infrastructure, distributed systems, and Python. Prior to his work at DigitalOcean he was an SRE helping build and maintain a highly available hybrid multicloud PaaS. He is an avid programmer, musician, educator, and writer/blogger. In his spare time he enjoys reading, camping, kayaking, and exploring new places.",
            "Title": "Building Docs like Code: Continuous Integration for Documentation",
            "Description": "It is common for developers to overlook the documentation of their works. They are either on a time crunch, lack the proper tooling, or simply just forget to create and update the documentation. Whatever the cause behind this, it is not a proper excuse for not keeping the documentation up to date. However, for all our development processes there are few as neglected as the documentation process. Documentation should be treated as important as the code that makes up the project. So, let’s move the documentation into the code. With modern documentation tools such as MkDocs and Sphinx, both of which are Python powered tools, and Continuous Integration tools we can now include docs in the commit. They can be reviewed in code reviews, built and versioned in a CI tool, and even tested for things such as correct code examples and broken links. This is the process that the developer knows, understands, and enjoys. I introduced a team to this exact workflow and a working pipeline; all they had to do was keep the documentation up to date. This team currently has some of the most up to date documentation in a company of near two thousand engineers, and they never complain about writing/updating documentation. It’s just part of the workflow.\nAttendees will walk away with a new mindset on how to handle documentation, a list of tools that can aid in this process, and a proven, easy-to-implement method that works well for real engineers in a production setting.",
            "Video_link": "https://youtu.be/4SwdVMKhbn4",
            "Video_id": "4SwdVMKhbn4",
            "viewCount": 1148,
            "likeCount": 48,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 7
        },
        {
            "Author": "Matt Bachmann",
            "Bio": "",
            "Title": "Transitioning from developing software to developing people: A firsthand experience",
            "Description": "Developing your career is building skills to grow the impact you have on an organization. After a certain point engineers typically decide to either go down an individual contributor path or a management one. Recently, I decided to try engineering management. My company had me manage six engineers in a recently formed team. In my first six months as a manager I developed the team’s process for getting work done, learned the basics of managing career development, and positioned my team within the larger engineering organization. I also learned about balancing competing priorities and moving a diverse set of personalities and desires towards a common goal. \n    In this talk I intend to talk specifically about the role of a manager of a single team. I will go over the types of problems a manager is responsible for and discuss the value a good manager can bring to a team/organization. I will help attendees understand the perspective of their current manager and help them decide if management is something they would be interested in trying out themselves.",
            "Video_link": "https://youtu.be/x7IwVaQgUAM",
            "Video_id": "x7IwVaQgUAM",
            "viewCount": 390,
            "likeCount": 16,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Deepak Kumar Gupta",
            "Bio": "Deepak K Gupta (a.k.a Daksh) is Founder & Software Crafter @ www.CodesBay.com. He is currently engaged in software development & consulting multiple organizations on cloud migration and building applications using A.I. and M.L. Prior to CodesBay, Deepak has worked as a Senior Software Architect in NOKIA\nDeepak is also a content creator and he publishes his contents on YouTube, LinkedIn, Instagram, TikTok, and Medium. The contents are for all ages and mainly revolve around software development.  \nDeepak is also a public speaker and has spoken at multiple global platforms and conferences which includes PyCon US.",
            "Title": "Saved by In-Memory NoSQL - A hitchhiker guided to Black Box debugging of Python Production Code",
            "Description": "If you’ve ever heard about or experienced a scenario where a production python bug can’t be fixed because we’re not able to reproduce the same, sometimes even after adding additional logs, then this session is for you.\nBlack box debugging is an idea where we add low footprint and encoded debug logs in the production code which drastically increases the chances of detecting the cause of a bug without requiring a recurrence with additional logs (read Debug Logs).\nTraditionally, we tend to include a limited amount of logs in the production code because writing the logs on the disk is a costly affair and can potentially impact the performances, but at the same time if something goes wrong, then we need the logs to debug the system. \nSo what if I tell you that you can have debug logs in the production code without impacting the performance of the code…!!! I bet you’ll be pleasantly surprised.  \nWelcome to the world of harnessing an unexpected and unintended benefit of In-Memory NoSQL databases which revolutionized the way we write debug logs for our python code. \nIn this talk, I’ll talk about how we use In-Memory NoSQL with python code and get persistent logs without impacting the performance of the production code. \nThis talk is for all Python programmers irrespective of their expertise level",
            "Video_link": "https://youtu.be/NjMTf2UWPsw",
            "Video_id": "NjMTf2UWPsw",
            "viewCount": 437,
            "likeCount": 18,
            "dislikeCount": 2,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Łukasz Langa",
            "Bio": "ambv on Github. Python core developer, Python 3.8 release manager, creator of Black, pianist, dad. Likes analog modular synthesizers, immersive single-player role playing games (Fallout, Elder Scrolls), and single malt Scotch whisky. In his free time helps EdgeDB build a new generation object-relational database for the masses.",
            "Title": "AsyncIO + Music",
            "Description": "Can Python help a musician play hardware instruments? Is there anything specific about AsyncIO that makes it well suited to the task? Come see how AsyncIO can be used to aid music production and realtime performance through MIDI processing.\nWe will cover transformations of incoming MIDI signal, driving hardware instruments with a shared clock, as well as generative music. All production-grade.\nIf you’re curious about AsyncIO and wanted to see it in action in a unique setting, this talk is for you! Music theory knowledge not required.",
            "Video_link": "https://youtu.be/02CLD-42VdI",
            "Video_id": "02CLD-42VdI",
            "viewCount": 1617,
            "likeCount": 66,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 3
        },
        {
            "Author": "Kathryn Lingel",
            "Bio": "Kathryn has been coding in Python as a student, engineer, and/or hobbyist for over 10 years, but the thrill of making computers do what she tells them to do never gets old. In her free time she loves tweeting about corgis, making bots to tweet about corgis for her, taking selfies with dinosaur statues, and playing songs on acoustic guitar that were never meant for acoustic guitar.",
            "Title": "Pyambic Pentameter: generating rhyming and metered poems with Markov chains and NLTK",
            "Description": "a strategy to generate a rhyme / without a human spending any time\nComputers may not yet be able to write poetry with soul, but we can teach them to write poetry with style! By combining Markov chain random text generation with a pronunciation dictionary in Python’s Natural Language ToolKit (NLTK), we can generate a poem that has both rhyme and meter.\nRandom text generation is a fun, beginner-friendly project with a lot of potential depth for the curious and creative. This talk will cover how to generate random writing based on a source text, as well as how to use NLTK to enhance the output, and conclude with a brand new Shakespearean sonnet!",
            "Video_link": "https://youtu.be/2ymZVpuqvSc",
            "Video_id": "2ymZVpuqvSc",
            "viewCount": 281,
            "likeCount": 19,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Vinayak Mehta",
            "Bio": "Open-source Human. Data Engineer. PyData Bangalore organizer. I love building tools that make people’s lives easier.",
            "Title": "The Hitchhiker's Guide to CLIs in Python",
            "Description": "Command-line applications and interfaces are used by both newcomers and experienced Python developers everyday. But do you know how they came to be? Hop on to this ship as we go through the CLI galaxy and look at its history, explore the CLI anatomy and discover some Python packages that can help us create them.\nWe’ll then look at some widely used CLIs of our time. And emulate one of them by creating our own CLI using Click. Finally, we’ll package it and publish it on PyPI. Are you ready to travel faster-than-light using this ship’s Infinite Improbability Drive? Carry your towel!",
            "Video_link": "https://youtu.be/Hn-syMunNy8",
            "Video_id": "Hn-syMunNy8",
            "viewCount": 1099,
            "likeCount": 32,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Lorena Mesa, Elaine Wong, Mariatta",
            "Bio": "Political scientist turned coder, Lorena Mesa is a data engineer on GitHub’s software intelligence systems team, Director and Vice-Chair, Elect on the Python Software Foundation, and PyLadies Chicago co-organizer. One part activist, one part Star Wars fanatic, and another part Trekkie, Lorena abides by the motto to “live long and prosper”.",
            "Title": "9 Years of PyLadies: Lessons Learned and What Comes Next",
            "Description": "9 years ago an initial group of 7 women met at PyCon USA 2011 began the world of what we know today as PyLadies. Since 2011, PyLadies has grown to 100+ chapters worldwide and the growth doesn’t seem to be stopping anytime soon! What has made PyLadies so successful in the past - it’s decentralization and high degree of chapter autonomy - has presented PyLadies with unseen new challenges in 2020 such as burnout, resource stagnation, and ultimately not allowed PyLadies to respond to the global community of 2020.\nJoin regional PyLadies organizers as they present what PyLadies has in store for the future including a global vision for community engagement and open source projects open to all.",
            "Video_link": "https://youtu.be/KRwpY2TixAs",
            "Video_id": "KRwpY2TixAs",
            "viewCount": 331,
            "likeCount": 10,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Elizaveta Shashkova",
            "Bio": "Elizaveta Shashkova is a Software Developer of the PyCharm IDE at JetBrains. She’s been working on debugger for several years and now she’s focused on Data Science tools.",
            "Title": "The Hidden Power of the Python Runtime",
            "Description": "Many people like Python for its simplicity and beauty. But every statement in Python, even the simple one, produces a lot of events during the program execution. These events are usually hidden from a user, so it helps developers to skip low-level implementation details and focus on bigger things.\nAt the same time many parts of this hidden information are very useful and interesting to examine. The good news is that the Python Runtime allows to retrieve it really simply, so there is no need to configure additional libraries or pass additional parameters to interpreter. Everybody can do it right inside their Python code.\nDuring this talk we will learn how Python allows to inspect current program state during the execution. We will learn about Python memory model, variables, frame objects and about useful information they store. After that we will discuss several powerful tools which are based on the runtime information and which can be very helpful for any Python programmer in their everyday life.",
            "Video_link": "https://youtu.be/yr6E7FwK_Hw",
            "Video_id": "yr6E7FwK_Hw",
            "viewCount": 1442,
            "likeCount": 67,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 9
        },
        {
            "Author": "Shauna Gordon-McKeon",
            "Bio": "Shauna Gordon-McKeon is a freelance technology consultant with a background in open source project management and Python programming. Her current focus is on improving both the governance of technology and governance technologies.",
            "Title": "Organizing To Improve Your Workplace: Know Your Rights",
            "Description": "If there’s a problem with your code, you can file a bug report. But what do you do when there’s a problem with your workplace?\nAll workers, including tech workers, have the right to try and improve our workplaces. This talk will give you an overview of your rights, with a special focus on issues that commonly arise in the tech industry, such as workplace harassment, overuse of non-disclosure agreements and forced arbitration clauses, and misclassification of contractors. We’ll also talk about what you can do when your company does something unethical, following the “Bargaining for the Common Good” model used by workers around the country to fight poverty, systemic racism, and climate change.",
            "Video_link": "https://youtu.be/mWKygyFir54",
            "Video_id": "mWKygyFir54",
            "viewCount": 470,
            "likeCount": 8,
            "dislikeCount": 4,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Wendi Dreesen",
            "Bio": "Wendi is currently an R & D Engineer at her current employer. Her primary roles are designing, building, and testing remote instrumentation control systems in addition to past roles operating, debugging, and maintaining muon detectors and a room-sized electron accelerator. She has a BSEE from the University of New Mexico and a MSEE from Stanford University.",
            "Title": "Mixing a Raspberry Pi with Python into a 5th Grade Science Fair Project",
            "Description": "I am proposing a talk that describes how to get started using a Raspberry Pi with Python. My child wanted to do a science fair project this year using the Raspberry Pi to collect the data. The project was to measure how long marbles would take to travel down different types of tracks: linear and curvy.\nIn the talk I present a few tips that should help to make a successful project. Then I proceed to describe the project in detail and how we broke it down into steps to get it completed.",
            "Video_link": "https://youtu.be/YB9aGx5zpto",
            "Video_id": "YB9aGx5zpto",
            "viewCount": 194,
            "likeCount": 3,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Hank Preston",
            "Bio": "Focusing on putting theory into practice, I do #NetDevOps and automation in #DevNet Sandbox.  I started my career in networking like many engineers, “conf t”ing and “router rip”ing, and those skills and experience shape the way I approach network automation. I’m super passionate about helping bring networking and network engineers into the new programmable age.",
            "Title": "Introduction to Writing Network Tests with pyATS",
            "Description": "How do you test that your network is healthy?  You probably ping a few things, run some show commands, and watch for open trouble tickets.  I don’t think I’ll stir up a ton of controversy by saying that’s a really bad method.  With the move towards network automation, NetDevOps, and Network Reliability Engineering (NRE), we need to have robust, repeatable tests to check the state of the network from Layer 1 to 7.  \npyATS is an open source network test framework that was built by software developers for network developers.  It provides all the tools automation engineers need to describe test cases, run jobs, gather reports, and make the entire process part of your network automation pipeline.  In this talk, we’ll look at everything you need to write your first few test cases, and discuss strategies for what you should test, and when.",
            "Video_link": "https://youtu.be/tFeVdazq0O0",
            "Video_id": "tFeVdazq0O0",
            "viewCount": 1320,
            "likeCount": 53,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Cristián Maureira-Fredes",
            "Bio": "",
            "Title": "C++ ♥ Python: from modules to hybrid applications",
            "Description": "Extending Python with C is a technique that many popular modules use for OS-level operations, serialization, performance, and more, but dealing with C code is not simple: you need to take care of memory, understand pointers, and write many lines of code for simple tasks. Luckily for you, there is C++.\nWait! Don’t be scared!\nI know maybe you heard bad stories and saw complicated pieces of C code, but: are you aware of how C has been evolving?\nThe latest C++ standards include many goodies that smell a bit of Python, and I will show them to you.\nDuring this talk, you will learn how to include C features into CPython modules, how to create hybrid applications**, and even to extend existent C applications with Python, making them scriptable**.\nThis talk is intended for developers who are familiar with Python and know basic C, but you don’t need to know any C++ to take the most out of it.",
            "Video_link": "https://youtu.be/klCfoGCwmMg",
            "Video_id": "klCfoGCwmMg",
            "viewCount": 459,
            "likeCount": 15,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Flávio Juvenal",
            "Bio": "Flávio is a software engineer from Brazil and partner at Vinta Software (www.vinta.com.br). At Vinta, Flávio builds high-quality web and data products, from UX to code, using mostly React and Django.",
            "Title": "1 + 1 = 1 or Record Deduplication with Python",
            "Description": "How to find duplicate records in a dataset without unique identifiers, like the SSN for US citizens? The answer is to use Record Deduplication techniques: look for matches by cleaning and comparing attributes in a fuzzy way. In this talk, you’ll learn with Python examples how to do this without needing any expert Data Science knowledge.\nThere are several critical applications of Record Deduplication in government and business. For example, by deduping records from Census data, the Australian government was able to find there were 250,000 fewer people in the country than they previously thought. This reduction impacted the estimations of government agencies and even caused the revision of economic projections. Similarly, businesses can use record deduplication techniques to clean up customers’ data. In this talk, you’ll learn with Python examples the main concepts of Record Deduplication: what kinds of problems can be solved, what’s the most common workflow for the process, what algorithms are involved, and which tools and libraries you can use. Although some of the discussed concepts are related to data mining, any intermediate-level Python developer will be able to learn the basics of how to dedupe data using Python.",
            "Video_link": "https://youtu.be/eMI8lwQl3Dc",
            "Video_id": "eMI8lwQl3Dc",
            "viewCount": 237,
            "likeCount": 11,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Hannah Stepanek",
            "Bio": "Hannah is a full stack developer with a passion for performance. She previously worked at Intel where she built a data analytics application for detecting and root causing post silicon test results and Hypothesis on an application to annotate the web. Last year she wrote a book on how to use Pandas focusing on performance, spent 6 months programming entirely in JavaScript, and built her company a more performant proxy server using Nginx and Lua. In her free time she enjoys show jumping her horse and playing board games.",
            "Title": "Let's talk Databases in Python: SQLAlchemy and Alembic",
            "Description": "What’s an ORM? Is there a way to write database queries so that they are compatible with multiple types of databases? How do you make database changes (such as adding a new table or a new column) safely? What is a connection pool and why is it useful? What are some things that can go wrong when operating at scale? Is lazy loading slowing you down? In this talk we’ll take a deep dive into how the Python libraries SQLAlchemy and Alembic make managing production databases simple, efficient, and painless so you can get back to feature development.",
            "Video_link": "https://youtu.be/36yw8VC3KU8",
            "Video_id": "36yw8VC3KU8",
            "viewCount": 570,
            "likeCount": 21,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Reuven Lerner",
            "Bio": "Reuven is a full-time Python trainer. In the last year, he taught at companies in the US, Europe, Israel, India, and China. Reuven also offers more than 10 online Python courses, including “Weekly Python Exercise,” a family of problem-based courses for improved Python fluency. He writes the free, weekly “Better developers” newsletter (read by more than 15k Python developers) and “Trainer weekly” (for technical trainers), and frequently posts about Python on Twitter, YouTube, and his blog. Reuven’s book, “Python Workout,” was recently published by Manning. Reuven lives with his wife and children in Modi’in, Israel.",
            "Title": "Function dissection lab -- learn how functions work by examining their innards",
            "Description": "When you invoke a function, how does it know how many arguments to expect?  How does it distinguish between local and global (and enclosing) variables?  How does it know that you defined the function with args and/or *kwargs?  And where does it store such things as docstrings, annotations, and defaults?\nThe short answer is that Python functions are objects – no different from integers, strings, and dicts. And like all other bjects,\nfunctions have attributes. It turns out that those attributes are the source of functions’ power.\nIn this talk, we’ll peek into function attributes, gaining an understanding of (and appreciation for) the way in which functions are built.  We’ll also see the relationship between attributes, functions, and Python bytecodes.  And while we’ll be dissecting many functions, I can assure you that none of them will be harmed in our quest for deeper understanding.",
            "Video_link": "https://youtu.be/QR9W81P7yTw",
            "Video_id": "QR9W81P7yTw",
            "viewCount": 937,
            "likeCount": 48,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Neeraj Pandey",
            "Bio": "Neeraj is a sophomore student at Ashoka University where he is pursuing Computer Science and Finance. He’s been interested in Generative Art, Native Web Applications, trading strategies, and algorithms. In his free time, he loves to play frisbee, write poems and contribute to open-source. Most of his open-source contributions go into mentoring Google Code-In students and volunteering PyData Delhi where he helps organizing conferences and meetups.",
            "Title": "The joy of creating art with code.",
            "Description": "Art is everywhere and it’s beautiful. Unleash the creative artist inside you with the beauty of Generative Art. Learn how algorithms are used to create these aesthetic art forms, how motion and structures emit sounds and what toolkits are required to do so. The talk will take the audience to a small history of Generative Art and how autonomously these art forms are created using algorithms with various examples using Processing, PyCario and more.",
            "Video_link": "https://youtu.be/Xjv1G0suPF8",
            "Video_id": "Xjv1G0suPF8",
            "viewCount": 454,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Catherine Nelson",
            "Bio": "Catherine Nelson is a Senior Data Scientist for Concur Labs at SAP Concur, where she explores innovative ways to use machine learning to improve the experience of a business traveller. She is particularly interested in privacy-preserving ML and applying deep learning to enterprise data. She is also co-author of the forthcoming O’Reilly publication “Building Machine Learning Pipelines”, and she is an organizer for Seattle PyLadies.",
            "Title": "Practical privacy-preserving machine learning in Python",
            "Description": "Machine learning is hungry for data, usually collected from users of a product and often including a lot of personal or sensitive information. What if we could build accurate machine learning models while still preserving user privacy? There’s a growing number of tools in Python to help us achieve this, ranging from federated learning, where a user’s data remains on their own device, to algorithms for training models on encrypted data. In this talk, I’ll tour the landscape of these tools and review what works, what doesn’t work, and where they fit in a machine learning pipeline.\nData privacy is a huge concern for everyone in tech these days, thanks to both legislation such as the GDPR, and user opinions driven by scandals in the media. Machine learning is at the forefront of this because it’s hungry for large amounts of training data, but it’s also an area where there’s lots of research on developing solutions that protect user privacy.\nWhen I started learning about privacy-preserving machine learning, I found a bewildering number of research papers, introducing some really cool solutions, but very little practical advice on how to apply them in a real-world situation. This is the talk I wish I could have attended at the start of my learning journey! I’ll review the landscape of Python solutions for privacy-preserving ML and show how they fit into a machine learning pipeline. I’ll explain the tradeoffs of each method and also talk a little about the ethics of using personal data for training ML models. Tools and packages covered will include TensorFlow Privacy, TensorFlow Encrypted and PySyft.",
            "Video_link": "https://youtu.be/NUk6QN02UxQ",
            "Video_id": "NUk6QN02UxQ",
            "viewCount": 270,
            "likeCount": 2,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Maria Jose Molina Contreras",
            "Bio": "",
            "Title": "How to build an intelligent “indoor garden” with microcontrollers, CircuitPython, and IoT.",
            "Description": "Most people around the world are getting more and more interested in living a long and healthy life nowadays. And many studies have proven that growing house plants, as long as being a trend, improves health. \nThe truth is, we are so busy with work, and even when we get home, that we do not have enough time to properly water our plants when they need it. \nIn this talk, you are going to learn how to build a functional and beginner friendly system to keep your plants alive using different sensors, microcontrollers and CircuitPython. \nThis system is going to water your plants based on their necessities and, step by step, you are going to add components and functionalities to the system; for instance, you will give your plants “a voice” to inform you about their deficiencies.\nMoreover, in this project, you will learn how to create a Web application with Flask, how to set up a Raspberry Pi as a local server and how to use a cloud IoT service for Data Analysis.\nFinally, you will see how Circuitpython can play an amazing role in these kind of situations, by helping plants to survive longer, and by making our responsibility lighter. This will also help you to understand that it is an excellent choice to start programming hardware and connected devices for everyone!",
            "Video_link": "https://youtu.be/8STo1-rRV1E",
            "Video_id": "8STo1-rRV1E",
            "viewCount": 482,
            "likeCount": 22,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Terri Oda",
            "Bio": "Terri specializes in saying no and explaining things, which either describes her professional work as an open source security expert, her personal time as a the parent of a child whose favourite phrase is “what happened?” or her volunteer work bringing new contributors into Python projects through Google Summer of Code.",
            "Title": "Using Python to Detect Vulnerabilities in Binaries",
            "Description": "Detecting known software vulnerabilities is hard to do perfectly, but it’s easy to get part way there. The CVE Binary Tool is a tool that detects issues in a few components but has grand ambitions. Learn how it works, how to use it & how to improve it so together we can help everyone be more secure.",
            "Video_link": "https://youtu.be/k3fM9KqKfTg",
            "Video_id": "k3fM9KqKfTg",
            "viewCount": 371,
            "likeCount": 16,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Shreya Khurana",
            "Bio": "As a data scientist at GoDaddy, Shreya works on language systems and unstructured multilingual text data.",
            "Title": "Bonjour mademoiselle! Wie geht es dir? Wǒ hěn hǎo. Dhanyawaad -How multilingual is your NLP model?",
            "Description": "Natural language is constantly evolving. With social media having its own language and interactions becoming more global, NLP models need more than just monolingual corpora to understand and make sense of all this data. Roughly, 50% of the world speaks two or more languages. This comes as a challenge to NL systems because conventional models are trained to understand one language or only translate from one to the other. In this talk, we’ll focus on Natural Language Understanding (NLU) for small multilingual texts.\nA key step in building NLU systems is language identification. First, we’ll give an introduction to existing frameworks for this task in Python like cld3, langid, langdetect and will also have a short discussion on their shortcomings. \nAnother area of concern is transliterated and code-switched text, which consists a combination of two or more structurally different grammars and vocabulary. This type of data can be clearly seen in Tweets and comments on Facebook as well as product reviews. What makes this problem very challenging is the lack of annotated datasets and the added noise of having no “correct” grammar and spelling. We discuss the approaches to solve this using web crawlers and self-generated datasets.\nThe next section of this talk will be on using the multilingual BERT model released by Google, which is trained in 104 languages. We’ll see some examples of how this model performs when given text pieces in different languages. In the final section, we’ll discuss how to evaluate the model for different tasks.",
            "Video_link": "https://youtu.be/hYZQaTeowHQ",
            "Video_id": "hYZQaTeowHQ",
            "viewCount": 388,
            "likeCount": 8,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Chris Seto",
            "Bio": "Chris Seto is a self-taught software engineer that started his career 6 years ago. He’s passionate about developing scalable, maintainable, and robust systems. In July 2019 he joined Cockroach Labs to develop their Database as a service platform.",
            "Title": "Big O No: Django ORM runtime complexity and how to avoid it using LATERAL JOINS",
            "Description": "N+1 queries are as common as blog posts about how to solve them. What happens when you want to get a list of blog posts, the comments on them, and the comments’ respective authors? An exponential number of queries. The rise of GraphQL and REST APIs that provide “include” semantics make these situations increasingly common and painful. Clever use of prefetch_related and select_related may help in a pinch but never fully solve the problem. Learn how to identify these inefficient queries and optimize them using SQL aggregations and LATERAL JOINs.",
            "Video_link": "https://youtu.be/GJUL3glrKvA",
            "Video_id": "GJUL3glrKvA",
            "viewCount": 420,
            "likeCount": 20,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Pratyush Das",
            "Bio": "Pratyush Das is an undergraduate majoring in Computer Science in India. He has experience developing software for High Energy Physics, having worked as a Visiting Scientist at Fermi National Accelerator Laboratory for over six months on fellowships awarded by DIANA-HEP and IRIS-HEP. He was also the only undergraduate accepted to the CoDaS-HEP summer school at Princeton University. He is the co-author of uproot - a ROOT I/O library written purely in python and numpy. uproot has been a runaway success in the High Energy Physics world getting tens of thousands of downloads.",
            "Title": "Python in High Energy Physics",
            "Description": "High Energy Physics is the study of the most fundamental constituents of matter and how these elementary particles interact. Often synonymous to Particle Physics, High Energy Physics seeks to find the secrets of the Universe, one of the recent major discoveries being that of the Higgs Boson that confirmed the Standard Model that dictates how all the forces in the Universe interact with each other. High Energy Physics is probably the physics sub-field that has adopted Python most rapidly, only second to Astrophysics.  \nThe talk starts with a look at how computing has looked like in the field of High Energy Physics in the past and how a lot of physicists played major roles in the development of Computer Science. It then explores the emergence of Python as the language of choice for several physicists and two of the major libraries that have been vital to the adoption of Python in the High Energy Physics community - cppyy and uproot. These are especially important since they demonstrate the different ways one could approach shifting the High Energy Physics community from C++ to Python successfully. The talk will focus on a review of where and how Python is used in the High Energy Physics community and how it is slated to look like in the future. \nHigh Energy Physics has its own python toolkit, scikit-hep which comes with a set of python libraries for use by physicists. The Scikit-HEP project is a community-driven and community-oriented project with the aim of providing Particle Physics at large with an ecosystem for data analysis in Python. It is also about improving the interoperability between High Energy Physics tools and the scientific ecosystem in Python. \nThis year is ideal for this particular talk, being the year when according to some available data, Python usage trumps C++ usage in several High Energy Physics experiments at CERN - as some physicists have dubbed it, this is the year of Python in High Energy Physics.",
            "Video_link": "https://youtu.be/jClVsR6XfdI",
            "Video_id": "jClVsR6XfdI",
            "viewCount": 409,
            "likeCount": 12,
            "dislikeCount": 3,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Rebeca Sarai",
            "Bio": "",
            "Title": "Privacy-preserving methods: Building secure projects",
            "Description": "Customers’ data is important. The number of privacy laws in recent years has grown from 20 to 100, to name a few: PCI compliance in the payment industry, the European GDPR regulation, and the Brazilian LGPD. All these new regulations attempt to bridge an old gap: data anonymity. How to handle data and protect the individuals comprised in it? Companies often face lawsuits to compensate for personal information breaches in their database. \nMany times production data is copied onto test, QA or staging environments, only to be followed by exposure to the eyes of testers, receivers, or unauthorized developers on machines less protected than production environments. It is not seldom for files also to be shared with external partners, who often require but a small part of the data transferred, and granting access to user’s data might be a breach. If in one hand sharing data is both necessary and inevitable, on the other technologies that assure the privacy of individuals details are no longer only desirable, but essential.\nIn this talk, we will approach two important topics: how to manage data whilst securing users’ personal information and how to do it in machine learning models. Exposing different techniques of anonymization and pseudonymization (k-anonymity, differential privacy, and others), showing that solving the anonymity problem is much more complex than replacing names, last names, and social security numbers.",
            "Video_link": "https://youtu.be/jKlJEPSZAYo",
            "Video_id": "jKlJEPSZAYo",
            "viewCount": 234,
            "likeCount": 5,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Igor Ghisi",
            "Bio": "Igor T. Ghisi is a software developer with B.Sc in Computer Science and M.Sc in Computational Mechanics. Has worked for 10 years in the largest research center of Latin America, in Rio de Janeiro, building software for R&D in engineering using agile practices, with focus in the Oil & Gas Industry. Developed software for 3D Mesh Generation, Mesh Visualization, Reservoir Simulation, Uncertainty and Multi-disciplinary Optimization. Switched to web development in the last 4 years to solve engineering problems using web and cloud technologies.",
            "Title": "Write Less and Test More with Data Regression Testing",
            "Description": "As data structures of a project increases in size and complexity, it becomes harder and harder to preserve test completeness. Testing objects with dozens of attributes and arrays with hundreds of values could turn into a laborious task. Often, programmers let these kind of data partially tested, especially if the required code coverage was already achieved.\nIn this talk we’ll show how to increase test completeness for data structures by applying data regression testing. We’ll be presenting pytest-regressions, a pytest plugin that helps to test datasets and objects by automatically serializing expected data on disk and later checking test results against it. We’ll also show how pytest-regressions make it easier to inspect test data and debug failing tests. The talk will demonstrate examples of data regression being applied to numerical algorithms, web APIs, Flask views and SQLAlchemy models.",
            "Video_link": "https://youtu.be/YBuVGx3EYSY",
            "Video_id": "YBuVGx3EYSY",
            "viewCount": 884,
            "likeCount": 45,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Aly Sivji",
            "Bio": "Aly Sivji is a Canadian expat living in Chicago. By day, he builds backend systems at Numerator. By night, he is a co-organizer of the Chicago Python Users Group (ChiPy). Aly is an active participant in the ChiPy Mentorship Program and he loves helping intermediate developers become experts. Outside of Python, Aly enjoys cycling, reading, and rewatching old TV shows.",
            "Title": "If Statements are a Code Smell",
            "Description": "if statements are elements of a programming language that allow us to control what statements are executed. By chaining together a series of if statements, we can solve any problem we can think of. But code with too many if statements is hard to read and even harder to change. Workarounds that once allowed us to move fast, now get in the way when we go in to make modifications. It doesn’t have to be this way!\nThis talk demonstrates HOWTO handle complex conditional logic with simple Python classes. The material will be presented in the context of a code refactor for an open-source project: we examine the initial solution featuring duplicate if statements, show how hard it is to make a change, and walk through the process of refactoring if blocks into polymorphic classes. The case study has been simplified to illustrate concepts you can apply to your own code.\nAfter this talk, you will be able to identify situations where an object-oriented solution can be used to improve software design. You will also be exposed to tradeoffs we need to think about before refactoring to higher-level abstractions.",
            "Video_link": "https://youtu.be/P0kfKqMHioQ",
            "Video_id": "P0kfKqMHioQ",
            "viewCount": 1792,
            "likeCount": 61,
            "dislikeCount": 5,
            "favoriteCount": 0,
            "commentCount": 5
        },
        {
            "Author": "Manojit Nandi",
            "Bio": "Manojit is a senior data scientist at J.P. Morgan Chase where he thinks a lot about issues pertaining to algorithmic fairness, AI ethics, and the cultural and anthropological implications of technology.",
            "Title": "The Limitations and Danger of Facial Recognition",
            "Description": "Biometric scanners, such as face recognition technology, have seen widespread adoption in applications, such as identifying suspected criminals, analyzing candidate’s facial expressions during job interviews, and monitoring attendance at schools.\nAs these technologies have become more pervasive, many organizations have raised potential concerns about the way these technologies schematize faces. Studies have shown commercial face recognition software has noticeably lower accuracy on darker-skinned individuals, and automatic gender recognition systems regularly misgender trans and non-binary individuals.\nIn addition, many scholars have written about the rise of techno-surveillance and looming threat of constant government tracking of citizens. In this talk, I will discuss these issues, and what we as technologists do to prevent building software that enables harm upon vulnerable populations.",
            "Video_link": "https://youtu.be/OS63Er80KJc",
            "Video_id": "OS63Er80KJc",
            "viewCount": 152,
            "likeCount": 2,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "James Bennett",
            "Bio": "Philosopher turned web geek. I like Django, Python 3, and the Oxford comma.",
            "Title": "A 🐍's guide to Unicode",
            "Description": "Unicode can seem like a scary topic, especially since people so often talk about it as a horrendously complex thing programmers should be afraid of 😱. But while Unicode does have some complexity, it doesn’t have to be scary! So this talk will demystify it: you’ll get to wave hello 👋 to Unicode, learn what it really is, how it works, and tips for how you can ❤️ Unicode in 🐍.",
            "Video_link": "https://youtu.be/olhKTHFYNxA",
            "Video_id": "olhKTHFYNxA",
            "viewCount": 551,
            "likeCount": 20,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 3
        },
        {
            "Author": "Emmanuelle Gouillart",
            "Bio": "Emmanuelle Gouillart is a scientific Python developer at Plotly, where she is a core developer of the plotly.py visualization library. She has a background in physics and materials science, and she has carried on scientific research and software development during the last years. She became a core contributor of Python’s popular image processing library scikit-image since a large part of her research relies on extracting quantitative data from image datasets. She has been a co-organizer of the Euroscipy conference during the last ten years, and she enjoys very much discussing with Python users about image processing and visualization at conferences.",
            "Title": "Building interactive applications for image data with Dash and scikit-image",
            "Description": "Images are an important class of data in science or business. Tasks such as quantification of organ geometry in medical imaging, or construction of training sets and pipelines for machine learning models, typically rely on a combination of interactive user annotations and image processing algorithms. In this talk I will present several open-source Python packages for interactive image processing, and how to combine them for advanced applications.\nDash is an open-source framework for building interactive analytical web applications in pure Python (or R). It comes with a set of interactive components which are the bricks from which to build easily custom analytical applications, such as figures using the plotly visualization library, interactive data tables, dropdowns, sliders, etc. These components interact together thanks to callbacks fired when a component is modified. After a demo of how to build an application with Dash, I will show how to interact with image data within Dash for exploring image characteristics or annotating images with various kinds of shapes (from rectangular bounding-box selection to freehand-brush painting of objects).\nIn addition, Dash applications can make use of Python data-science packages in order to use advanced algorithms to process user-provided annotations. I will focus mostly on scikit-image, and briefly mention machine learning / deep learning tools as well. scikit-image is a popular library for processing 2D and 3D images as Numpy numerical arrays, with a focus on scientific imaging and pedagogical example-based documentation. I will show how to use scikit-image for various image processing tasks, from basic preprocessing (e.g. normalizing image geometry or exposure) to advanced object segmentation tasks. I will finally show how combining scikit-image and Dash can result in advanced image processing applications,  which can be written quickly thanks to simple APIs and thorough documentation.",
            "Video_link": "https://youtu.be/fnNUMKH6TWI",
            "Video_id": "fnNUMKH6TWI",
            "viewCount": 349,
            "likeCount": 3,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Nina Zakharenko",
            "Bio": "Nina Zakharenko is a software engineer with over a decade of experience. She currently focuses on Python at Microsoft on the Cloud Developer Advocacy team. In the past, she’s written software for satellite control computers at HBO, code that’s helped people connect over their passions at Meetup, and implemented time-wasting features on Reddit. In her spare time, she enjoys snowboarding and hiking, drinking scotch, and tinkering with hardware, LEDs, and wearable electronics from her home base in Portland, OR.",
            "Title": "Goodbye Print, Hello Debugger!",
            "Description": "Still debugging your code with print? Learn how to level up your ability to troubleshoot complex code situations by using the power of a fully-featured debugger in this talk aimed at all levels of programming ability.\nDebuggers allow you to examine your program state, watch as the values of important variables change, and even modify the content of variables on the fly. Once I gave up using print to debug, my productivity as a programmer increased, and yours can too!\nI’ll showcase the variety of debugger tools available - from pdb, the simplest command line debugger that’s part of the standard library, to fancy graphical debuggers available in Python IDEs. Join me as we walk through real code together using debugger tools in a hands-on way to help us diagnose problems and bugs. The skills you’ll learn in this talk will allow you to quickly use these tools in your own code bases for fun, school, or work.",
            "Video_link": "https://youtu.be/5AYIe-3cD-s",
            "Video_id": "5AYIe-3cD-s",
            "viewCount": 1842,
            "likeCount": 101,
            "dislikeCount": 3,
            "favoriteCount": 0,
            "commentCount": 7
        },
        {
            "Author": "Brian Okken",
            "Bio": "Brian Okken is the host of the Test and Code podcast, co-host of the Python Bytes podcast, the author of the premier book on pytest: “Python Testing with pytest”. \nBrian Okken is a team lead and lead software engineer at Rohde & Schwarz where he spends about half his time testing hardware and software using Python.",
            "Title": "Multiply your Testing Effectiveness with Parameterized Testing",
            "Description": "Parametrization is one of the superpowers of pytest. It allows you to cover a huge number of test cases with a single test function. This speeds up test writing and makes test maintenance easier. This talk is a medium depth dive into pytest parametrization, with techniques you can use right away.\nThis talk will use of code examples, starting with a simple test then demonstrating 3 methods of parametrization, as well as test case identifiers and using generators.",
            "Video_link": "https://youtu.be/2R1HELARjUk",
            "Video_id": "2R1HELARjUk",
            "viewCount": 748,
            "favoriteCount": 0,
            "commentCount": 4
        },
        {
            "Author": "Alexandra Sunderland",
            "Bio": "Alexandra is a full-stack software engineer at Fellow.app in Ottawa, Canada, where she’s helping to build the future of work. She’s been working as an engineer for the last 8 years, from startups like Fluidware to large companies like SurveyMonkey. Alexandra regularly publishes blog posts and speaks internationally about tech and teams, all while designing and sewing clothes that incorporate custom 3D printed elements. Alexandra is also a the co-leader of the Slack Platform Community in Ottawa.",
            "Title": "From 0 to 60 in 2,592,000 seconds: How to quickly get engineers up to speed",
            "Description": "When anyone starts on a new team, there’s a ramp-up period where a ton of knowledge is transferred: there are new processes, names, tools, frameworks, and so many other different details to remember. Meanwhile, critical new relationships are started, and lasting impressions are formed. New team members that don’t get to follow a defined process during this time are at risk of not receiving all the information they need to be effective fast, and of not feeling valued by their team.\nAs an engineer that loves a good repeatable process, I decided that I’d like to make onboarding engineers a task that is both effective and scalable. If you’re bringing on one new engineer or fifty to your project, having a formalized process in place ensures that they can get up to speed on your project quickly, and receive a fair start on the team.\nWhether you’re a manager, a lead, or a developer eager to help out, you’ll learn how to create your own exceptional onboarding process, and hear about my own onboarding failures and eventual success.",
            "Video_link": "https://youtu.be/9c0ksQKizts",
            "Video_id": "9c0ksQKizts",
            "viewCount": 327,
            "likeCount": 9,
            "dislikeCount": 2,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Tania Allard",
            "Bio": "Tania is a Sr. Developer Advocate at Microsoft with vast experience in academic research and industrial environments. Her main areas of expertise are within data-intensive applications, scientific computing, and machine learning. One of her main areas of expertise is the improvement of processes, reproducibility and transparency in research, data science and artificial intelligence.\nShe is passionate about mentoring, open-source, and its community and is involved in a number of initiatives aimed to build more diverse and inclusive communities. She is also a contributor, maintainer, and developer of a number of open-source projects and the Founder of Pyladies NorthWest UK.",
            "Title": "Docker and Python: making them play nicely and securely for Data Science and ML",
            "Description": "Docker has become a standard tool for developers around the world to deploy applications in a reproducible and robust manner. The existence of Docker and Docker compose have reduced the time needed to set up new software and implementing complex technology stacks for our applications.\nNow, six years after the initial release of Docker, we can say with confidence that containers and containers orchestration have become some of the defaults in the current technology stacks.\nThere are thousands of tutorials and getting started documents for those wanting to adopt Docker for apps deployment. However, if you are a Data Scientist, a researcher or someone working on scientific computing wanting to adopt Docker, the story is quite different. There are very few tutorials (in comparison to app/web) and documents focused on Docker best practices focusing on DS and scientific computing. If you are working on DS, ML or scientific computing, this talk is for you. We’ll cover best practices when building Docker containers for data-intensive applications, from optimising your image build, to ensuring your containers are secure and efficient deployment workflows.\nAttendees will leave the talk feeling confident about adopting Docker across a range of DS, ML and research projects.",
            "Video_link": "https://youtu.be/Jq68axbKIbg",
            "Video_id": "Jq68axbKIbg",
            "viewCount": 1408,
            "likeCount": 33,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Kim-Adeline Miguel",
            "Bio": "Kim-Adeline is a software engineer at Microsoft working on the Python extension for VS Code. Prior to that, she dabbled with parallel programming in Singapore and worked as a front-end engineer in Denmark and in Vancouver. Other qualifications include propagating succulents 🌵 being able to hold crow pose for 3 breaths 🐦 and using emojis wherever possible 👋",
            "Title": "Decoding bias and narrative in competitive video games broadcasts with video analysis",
            "Description": "With video game competitions (also known as eSports) being broadcast on online streams and regular TV stations, in-game video producers have to balance between making the game accessible to casual viewers, and packing enough action on screen to keep regular players interested.  \nWhat they choose to show on screen also define the narratives surrounding the competing teams, building hype around them and setting implicit expectations (for example what character class is shown the most).  \nIn this talk we will walk through video analysis of professional Overwatch games to extract data, explore and validate a few hypotheses on what eSports broadcasters think viewers want to see.",
            "Video_link": "https://youtu.be/0HzbyQPKW9E",
            "Video_id": "0HzbyQPKW9E",
            "viewCount": 202,
            "likeCount": 6,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Anthony Shaw",
            "Bio": "Anthony is based in Sydney, Australia, and blogs about Python, software, and automation. Anthony is an open-source software advocate, Fellow of the Python Software Foundation, and a member of the Apache Software Foundation.",
            "Title": "Why is Python slow?",
            "Description": "When Python completes a comparable application 2–10x slower than another language, why is it slow, and can’t we make it faster?\nIn this talk, we’re going to explore different theories to understand what makes Python slow, what tasks it’s fast at executing, and how you can make it faster.\nThen, finally, we’ll explore what is coming in future versions of Python that might speed it up once and for all.",
            "Video_link": "https://youtu.be/I4nkgJdVZFA",
            "Video_id": "I4nkgJdVZFA",
            "viewCount": 1100,
            "likeCount": 64,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 4
        },
        {
            "Author": "Eric Ma",
            "Bio": "Eric is a data scientist at the Novartis Institutes for Biomedical Research. where he conducts biomedical data science research, focusing on machine learning methods to accelerate the development of medicines. Prior to Novartis, he was an Insight Health Data Fellow in the summer of 2017, and defended his doctoral thesis in the Department of Biological Engineering in the spring of 2017. He is also an open source software developer, making a variety of contributions to the PyData community.\nHis personal life motto is found in the Gospel of Luke 12:48.",
            "Title": "A careful walk through probability distributions, using Python",
            "Description": "In this talk, we will do more than just a random walk through probability. In particular, by using Python code as an anchor, we will explore what a probability distribution as an “object” is, especially in a modelling context. By the end of this talk, probability distributions, sampling (or generating data) from a probability distribution, and the basic terms of joint, conditional and marginal distributions, should be demystified for you, and you should leave with a solid working knowledge of probability to go further and deeper with Bayesian statistics beyond PyCon!",
            "Video_link": "https://youtu.be/G7SIcvWrAKs",
            "Video_id": "G7SIcvWrAKs",
            "viewCount": 209,
            "likeCount": 11,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Calvin Hendryx-Parker",
            "Bio": "Calvin Hendryx-Parker is an AWS Community Hero and the co-founder and CTO of Six Feet Up, a Python development and Cloud consulting company established in 1999. At Six Feet Up, Calvin establishes the company’s technical vision and leads all aspects of the company’s technology development. He provide the strategic vision for enhancing the offerings of the company and infrastructure, and works with the team to set company priorities and implement processes that will help improve product and service development. Calvin is the co-founder of the Python user group IndyPy, the largest tech meetup in Indiana with 1,700+ members.",
            "Title": "Finite State Machine (FSM) in Django",
            "Description": "Workflows are super powerful tools for automating business processes online. Our everyday life is full of workflows such as requesting time off from work. Many of these are actually Finite State Machines that move from state to state via transitions. Popular CMS’ such as Plone have rich support for workflows, but now with django-fsm we can build quick, lightweight business workflows for our applications. Plus, we have full audit logging and even build visualizations of our workflow to confirm with the business owners generated from the code.",
            "Video_link": "https://youtu.be/nG_ZsNxRz0o",
            "Video_id": "nG_ZsNxRz0o",
            "viewCount": 157,
            "likeCount": 5,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Javier Jorge",
            "Bio": "I’m a PhD student in Computer Science at Universidad Politécnica de Valencia (UPV). I received a B.Sc. in Computer Science from the UPV in 2014 and the Master’s degree in Artificial Intelligence, Pattern Recognition and Digital Imaging (MIARFID) from the UPV in 2015.\nI’m working as a researcher with the “Machine Learning and Language Processing” Group (MLLP) of the UPV and my research interests include Speech Recognition, Natural Language Processing, Pattern Recognition and Machine Learning.",
            "Title": "“Sorry, Could you repeat that again?” -  Speech Recognition with Python",
            "Description": "Nowadays, we are surrounded by devices that can listen to us: Alexa, Siri, Cortana, etc, and the interaction with them has become easier and easier, and more intuitive. The first challenge to communicate in a colloquial way with all these devices is to convert the voice signal to text. To do this, several approaches based on searching methods, algorithmic techniques, and machine learning are combined in very smart and interesting ways.\nIn this talk, I will introduce the underneath speech recognition systems that these devices utilize. This will be illustrated with a guided example where we will develop a system to recognize isolated words in Python.\nFinally, I will show how we are implementing these and more advanced techniques in our production systems, providing transcriptions for different companies and institutions, using Python in different parts of the process.",
            "Video_link": "https://youtu.be/D9i1lwC-3ZA",
            "Video_id": "D9i1lwC-3ZA",
            "viewCount": 113,
            "likeCount": 3,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Robson Luis Monteiro Junior",
            "Bio": "Robson is a developer since 2003 with a multifaceted life. Since 2014 transitioned the career to be a Data Engineer and use python to handle complex pipelines and glue other technologies. Living in Berlin, in the free time, he is an apprentice paramedical tattooer helping people to recover the self-esteem and run Olympic and ironman triathlon races.",
            "Title": "Polyglot data with python: Introducing Pandas and Apache Arrow",
            "Description": "Nowadays Python is synonymous of data, but not necessarily the best choice for some data tasks. For example, exchange data between different ecosystems is one of the challenges for Python. Pandas and NumPy are very efficient and de facto tools to deal with a reasonable amount of data with performance, but they are limited outside of the Python ecosystem. Acquire and exchange data might be painful due to the problem to write slow conversion code or generated unnecessary large files to talk with other ecosystems, likes large CSV files. Apache Arrow playing with Pandas is a great option as technologies that handle these problems with an excellent performance playing natively with Python. This talk aims to show how to work in a heterogeneous environment with data coming from another ecosystem, be handled inside the Python ecosystem and send back to another ecosystem transparently.",
            "Video_link": "https://youtu.be/yWR97VkLIzE",
            "Video_id": "yWR97VkLIzE",
            "viewCount": 92,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Matthew Rocklin",
            "Bio": "Matthew is an open source software developer in the numeric Python ecosystem. He maintains several PyData libraries, but today focuses mostly on Dask a library for scalable computing. Matthew worked for Anaconda Inc for several years, and now works for NVIDIA, where he continues to maintain Dask and use it to scale out the RAPIDS initiative to do scalable data science on GPU accelerated hardware.",
            "Title": "Deploying Python at Scale with Dask",
            "Description": "This talk discusses the challenges and options to scale Python with Dask on distributed hardware.  We particularly focus on how Dask gets deployed on cluster resource managers like Kubernetes, Yarn, and the cloud today.\nThe Python data science stack (Numpy, Pandas, Scikit-Learn and others) has become the gold standard in most data centric fields due to a combination of intuitive high level APIs and efficient low-level code.  However, these libraries were not originally designed to scale beyond a single CPU or data that fits in memory.  Over the last few years the Dask library has worked with these libraries to provide scalable variants, which do run on multi-core workstations or on distributed clusters.  This has allowed advanced users the ability to scale Python to handle 100+TB datasets.\nHowever, deploying Dask within an institution remains a challenge.  How do we balance load across many machines?  How do we share with other distributed systems running on those same machines?  How do we control access and provide authentication and security?  As more institutions adopt Python to handle scalable computation these questions arise with greater urgency.  This talk discusses the options today to deploy Dask securly within an institution on distributed hardware, and dives into some examples where this has had a large positive social impact.",
            "Video_link": "https://youtu.be/deX0GlW4uew",
            "Video_id": "deX0GlW4uew",
            "viewCount": 182,
            "likeCount": 5,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Daniel Imberman",
            "Bio": "Daniel Imberman is a full-time Apache Airflow committer, a digital nomad, and constantly on a search for the perfect bowl of ramen. Daniel received his BS/MS from UC Santa Barbara in 2015 and has worked for data platform teams ranging from early-stage startups, to large corporations like Apple and Bloomberg LP.",
            "Title": "Life Beyond Yaml: Bridging Data Science and Data Infrastructure with Apache Airflow",
            "Description": "When supporting a data science team, data engineers are tasked with building a platform that keeps a wide range of stakeholders happy. Data scientists want rapid iteration, infrastructure engineers want monitoring and security controls, and product owners want their solutions deployed in time for quarterly reports. Collaboration between these stakeholders can be difficult, as every data science pipeline has a unique set of constraints and system requirements (compute resources, network connectivity, etc). For these reasons, data engineers strive to give their data scientists as much flexibility as possible, while maintaining an observable and resilient infrastructure. \nIn recent years, Apache Airflow (a Python-based task orchestrator developed at Airbnb)  has gained popularity as a collaborative platform between data-centric Pythonistas, and infrastructure engineers looking to spare their users from verbose and rigid yaml files. Apache Airflow exposes a flexible pythonic interface that can be used as a collaboration point between data engineers and data scientists. Data engineers can build custom operators that abstract details of the underlying system and data scientists can use those operators (and many more) to build a diverse range of data pipelines.\nFor this 30 minute talk, we will take an idea from a single-machine Jupyter Notebook to a cross-service Spark + Tensorflow pipeline, to a canary tested, hyper-parameter-tuned, production-ready model served on Google Cloud Functions. We will show how Apache Airflow can connect all layers of a data team to deliver rapid results.",
            "Video_link": "https://youtu.be/zd_hWkOU-V0",
            "Video_id": "zd_hWkOU-V0",
            "viewCount": 228,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Colin Carrol",
            "Bio": "Colin Carroll is a software engineer at Google Research Cambridge. He is interested in statistical computing and visualization, particularly as related to Bayesian methods. He is heavily involved in open source: a core contributor to PyMC3, a Python library for Bayesian modelling and inference, as well as ArviZ, a Bayesian visualization and diagnostic library. He received his PhD in mathematics from Rice University, where he researched geometric measure theory.",
            "Title": "Getting started with automatic differentiation",
            "Description": "The derivative is a concept from calculus which gives you the rate of change of a function: for a small change in an input, how much does the output change? This idea turns out to be very important in natural sciences, and is used in many optimization algorithms, which find the maximum or minimum of functions.\nAutomatic differentiation is a technique for computing the derivative of a function. Python has a number of libraries implementing automatic differentiation, many of which are put to use for deep learning, but can be used on their own.\nIn this talk I will give intuition for the derivative and its high dimensional sibling, the gradient. We will take a tour of applications, including optimization and computational art, with examples using jax, TensorFlow, and PyTorch. We conclude with a brief description of alternative ways of computing derivatives in Python, and their relative strengths.",
            "Video_link": "https://youtu.be/NG21KWZSiok",
            "Video_id": "NG21KWZSiok",
            "viewCount": 480,
            "likeCount": 26,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        }
    ],
    "tutorials": [
        {
            "Author": "Eric Ma",
            "Bio": "Eric is a data scientist at the Novartis Institutes for Biomedical Research. where he conducts biomedical data science research, focusing on machine learning methods to accelerate the development of medicines. Prior to Novartis, he was an Insight Health Data Fellow in the summer of 2017, and defended his doctoral thesis in the Department of Biological Engineering in the spring of 2017. He is also an open source software developer, making a variety of contributions to the PyData community.\nHis personal life motto is found in the Gospel of Luke 12:48.",
            "Title": "Demystifying Deep Learning for Data Scientists",
            "Description": "Have you ever wondered what goes on behind the scenes of a deep learning framework? Or what is going on behind that pre-trained model that you took from Kaggle? Then this tutorial is for you! In this tutorial, we will demystify the internals of deep learning frameworks - in the process equipping us with foundational knowledge that lets us understand what is going on when we train and fit a deep learning model. By learning the foundations without a deep learning framework as a pedagogical crutch, you will walk away with foundational knowledge that will give you the confidence to implement any model you want in any framework you choose.",
            "Video_link": "https://youtu.be/gGu3pPC_fBM",
            "Video_id": "gGu3pPC_fBM",
            "viewCount": 2328,
            "likeCount": 60,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 5
        },
        {
            "Author": "Matt Harrison",
            "Bio": "Matt Harrison has been using Python since 2000. He runs MetaSnake, a Python and Data Science consultancy and corporate training shop.  In the past, he has worked across the domains of search, build management and testing, business intelligence, and storage. He has written many books on Python including: Machine Learning Pocket Refence, Effective PyCharm, Illustrated Guide to Python 3, and Learning the Pandas Library.",
            "Title": "Hands on Beginning Python",
            "Description": "Are you new to Python? Or do you feel like you grok the syntax, but would like to understand new idioms or where to use them? Want to watch an experienced Python developer create code from nothing? Instead of just covering the syntax, we will introduce most of Python as we build code together.\nBring your laptop, and we will program a predictive text engine from scratch together. Follow along as we start with IDLE (or your favorite editor) and a blank file and end with a tested, idiomatic Python module that will learn from any text we pass into it, and predict characters or words for us.",
            "Video_link": "https://youtu.be/fuJcSNUMrW0",
            "Video_id": "fuJcSNUMrW0",
            "viewCount": 3594,
            "likeCount": 62,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 5
        },
        {
            "Author": "Andrew Knight",
            "Bio": "Pandy Knight is the “Automation Panda” - a Pythoneer, consultant, and international speaker who loves all things about software. He specializes in building robust test automation solutions that run hundreds of tests continuously. Andy currently works full-time as the lead software engineer in test at PrecisionLender, but he also teaches part-time as an adjunct professor at Wake Technical Community College. Read his tech blog at AutomationPanda.com, and follow him on Twitter at @AutomationPanda.",
            "Title": "Hands-On Web App Test Automation",
            "Description": "When unit tests aren’t enough, how can we write reliable automated tests for Web apps in live browsers? It’s easy with Python! Let’s build a test project from the ground up using pytest and selenium to test DuckDuckGo searches. We’ll take a top-down approach and get our hands dirty with automation code at each layer. Learn everything from switching browsers to avoiding race conditions!",
            "Video_link": "https://youtu.be/XMMHpv54xxM",
            "Video_id": "XMMHpv54xxM",
            "viewCount": 830,
            "likeCount": 25,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Kimberly Fessel",
            "Bio": "Kimberly Fessel is a data science bootcamp instructor at Metis in New York City.  Her professional interests include natural language processing, data visualization, and data storytelling. Kimberly’s enthusiasm for teaching comes from her days as an academic. She holds a Ph.D. in applied mathematics from Rensselaer Polytechnic Institute and completed a postdoctoral fellowship in math biology at the Ohio State University.",
            "Title": "It's Officially Legal so Let's Scrape the Web",
            "Description": "Web scraping empowers you to write Python programs that collect data from websites automatically, and recent legal rulings support your right to do so!  This tutorial covers the breadth and depth of web scraping: from HTML basics through pipeline methods to compile entire datasets.  Participants should have working knowledge of Python fundamentals but need not have prior experience scraping.",
            "Video_link": "https://youtu.be/RUQWPJ1T6Zc",
            "Video_id": "RUQWPJ1T6Zc",
            "viewCount": 1101,
            "likeCount": 32,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 4
        },
        {
            "Author": "Sebastian Witowski",
            "Bio": "Sebastian is a freelancer and Python trainer who worked as a DevOps at CERN and recently started his own journey. He enjoys web development and operations. In his spare time, he likes to talk about Python, coding, and productivity.",
            "Title": "Modern Python Developer's Toolkit",
            "Description": "This is a tutorial that I wish someone gave to me when I first learned Python.\nPython is (relatively) easy and fun to learn, but there is a gap between “knowing how to write Python code” and “knowing the tools and good practices when writing Python code”. This tutorial will try to bridge this gap. It’s intended for beginners who know Python, but who are not sure how to write a Python project from scratch.\nIn this tutorial you will learn:\nTo follow all parts of the tutorial you need to have: VS Code, Docker, and a modern version of Python (at least 3.4, preferably 3.6 or newer) installed on your computer.",
            "Video_link": "https://youtu.be/WkUBx3g2QfQ",
            "Video_id": "WkUBx3g2QfQ",
            "viewCount": 2529,
            "likeCount": 59,
            "dislikeCount": 2,
            "favoriteCount": 0,
            "commentCount": 4
        },
        {
            "Author": "Katie McLaughlin",
            "Bio": "Katie has worn many different hats over the years. She’s currently a Cloud Developer Advocate at Google, Director of the Python Software Foundation, Django Software Foundation, and Conference Director for PyCon AU 2018/2019. When she’s not changing the world, she enjoys making tapestries, cooking, and seeing just how well various application stacks handle emoji.",
            "Title": "Deploying Django on Serverless Infrastructure",
            "Description": "Taking your DjangoGirls workshop website and hosting it on the Cloud is complex. Not complicated, just complex. The statefulness of Django out of the box compared to other Python web frameworks makes the migration from your own laptop to a hosted platform non-trivial. \nIn this tutorial, we will take a sample Django project from source control and local deployment to a hosted service using serverless infrastructure. This tutorial will use Google Cloud Platform, but concepts can be applied to any cloud platform.",
            "Video_link": "https://youtu.be/oYy9_4fm56o",
            "Video_id": "oYy9_4fm56o",
            "viewCount": 528,
            "likeCount": 15,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Husni Almoubayyed",
            "Bio": "Husni is a Ph.D. candidate at Carnegie Mellon University. Working in observational cosmology, he spends a lot of his time writing Python programs to unravel the mysteries of the universe around us\nHe is passionate about artificial intelligence and generally enjoys solving challenging interdisciplinary problems – from finance to music – in novel computational ways. Please visit https://husni.space for more information and ways to connect with Husni.",
            "Title": "Effective Data Visualization",
            "Description": "From picking the right plot for the particular type of data, statistic, or result; to pre-processing sophisticated datasets, and even making important decisions about the aesthetic of a figure, visualization is both a science and art that requires both knowledge and practice to master.\nThis tutorial is for python users who are familiar with python and basic plotting, and want to build strong visualization skills that will let them effectively communicate any data, statistic, or result. \nWe will use python libraries such as seaborn, matplotlib, plotly, and sklearn; and discuss topics such as density estimation, dimensionality reduction, exploring similar datasets, interactive plotting, and making suitable choices for communication. Drawing examples from datasets in the scientific, financial, geospatial (mapping) fields and more.",
            "Video_link": "https://youtu.be/cNXioWhEeJc",
            "Video_id": "cNXioWhEeJc",
            "viewCount": 974,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Keith Galli",
            "Bio": "Growing up I found programming as an outlet to creatively apply my passion for mathematics. This led me to get a BS & MEng in computer science from MIT.\nLately, I have been spending a lot of time working on my educational YouTube channel. My most popular videos are tutorials walking through data science libraries such as Pandas, Matplotlib, and NumPy. My channel has been able to accumulate over 20,000 subscribers and over 2 million views.\nIn my full-time role I work as a developer at a start-up called Posh Technologies. We build chatbots for financial institutions.",
            "Title": "Natural Language Processing (NLP) in Python - From Zero to Hero",
            "Description": "In the past year, massive developments have been made in the natural language processing field. Improvements in areas such as question answering, machine translation, and sentiment analysis have opened up doors to utilize NLP more effectively than ever before.\nIn this tutorial we will perform a brief overview of the field of NLP and look at the Python libraries that allow us to utilize different techniques and models. We will start with simple, traditional approaches to NLP that will provide us baseline for our models. As we progress in the tutorial we will look at some more advanced concepts that can give quick boosts to model performance. We will end by introducing state-of-the-art language models and how we can incorporate them into applications that we build.",
            "Video_link": "https://youtu.be/vyOgWhwUmec",
            "Video_id": "vyOgWhwUmec",
            "viewCount": 1486,
            "likeCount": 56,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 12
        },
        {
            "Author": "Mariatta Wijaya",
            "Bio": "Mariatta is a Python Core Developer, a software engineer at Zapier, Vancouver PyLadies co-organizer, and one of the founding members of the PyCascades conference. She moved to Canada almost two decades ago, and now lives in Vancouver with her husband and two children. In her free time, she contributes to open source, builds GitHub bots, fixes typos, and likes to tell you about f-strings. Her favorite emoji is :stuck_out_tongue_closed_eyes:.",
            "Title": "Say it with Bots!",
            "Description": "Let’s build a GitHub bot that can greet contributors to your project. As humans, we can’t always be up and running 24/7. It can be nice for your contributors if they can receive prompt response from you regarding their pull request instead of waiting until you’re back.\nIn this tutorial, we’ll go through several activities for building a GitHub App that can be easily installed in various repositories.\nYour GitHub bot can:\n- thank the maintainer for installing the bot\n- thank first time contributors for making a pull request to your repository\nLearn about GitHub APIs, GitHub Apps, and authentications through these fun activities! We’ll be using Python libraries like gidgethub, aiohttp, and asyncio. F-strings included!",
            "Video_link": "https://youtu.be/JWhywJHIMfs",
            "Video_id": "JWhywJHIMfs",
            "viewCount": 383,
            "likeCount": 6,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 2
        },
        {
            "Author": "Sergio Sanchez",
            "Bio": "Sergio Sanchez is a research associate at the PPIC Higher Education Center. His research interests include the achievement gap, migration, and data visualization. Before joining PPIC, he worked at the Davis Joint Unified School District as a data analyst, focusing on school climate issues. He also worked as a lead tutor for Davis Bridge, an afterschool program which provides academic support and mentorship to students of historically underserved communities.\nHis latest project, tacosdedatos, is a place for people from all levels of expertise to learn about data analytics and visualization in spanish.",
            "Title": "Geospatial Public Policy Analysis with GeoPandas",
            "Description": "\n- The Chronicle of Higher Education\nWhat if you could take the power of pandas and apply it to geospatial data?\nThat’s what GeoPandas does!\nIn this tutorial you will analyze openly available data and apply a GIS-lens to it! We’ll use data from the National Center for Education Statistics (NCES) to recreate the map above! We’ll use Integrated Post-secondary Education Data System (IPEDS) data to map out all the higher education institutions in the United States and analyze the results. We’ll look at the equity implications of Education Deserts and learn some really neat pandas and geopandas tricks in the process!\nThis tutorial is perfect for novice data analysts, pythonistas, social scientists, and journalists that want to learn about the powerful pandas and geopandas libraries and how to use it to analyze openly available data (and for those who’ve been using them but could learn a trick or two to make their workflow even more effective, reproducible and open). Some familiarity with jupyter and pandas is appreciated but not necessary. \nDo the words Title IV, PfP/PnP, census blocks, or IPUMS mean anything to you? No?! the more reason to join! Come learn something new!",
            "Video_link": "https://youtu.be/_eII-MqXlv0",
            "Video_id": "_eII-MqXlv0",
            "viewCount": 305,
            "likeCount": 8,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Santiago Basulto",
            "Bio": "Born in the beautiful Patagonia, Argentina. I’ve been coding for a long time; I enjoy coding and creating project, as well as learning new languages and technologies. In 2015 I co-founded RMOTR, a Data Science bootcamp, that was sold to INE in 2019.\nI love sports (Ultimate Frisbee, Rugby, Football), reading about Roman History, and having a great time with Tano (my Brittany Spaniel).",
            "Title": "Python Concurrency: from beginner to pro",
            "Description": "This is the ultimate concurrency tutorial. Aimed for beginners, we won’t skip the ugly parts (OS low level and computer science concepts). In this tutorial you’ll learn:\nThis tutorial will include coding examples for all the concepts in it, along with two main activities, in which we’ll be writing a web server both using multithreading and multiprocessing!\nAt the end of this tutorial, you’ll feel confident answering the following questions:",
            "Video_link": "https://youtu.be/18B1pznaU1o",
            "Video_id": "18B1pznaU1o",
            "viewCount": 1116,
            "likeCount": 45,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 1
        },
        {
            "Author": "Mike Müller",
            "Bio": "Mike Müller has been intensively using Python since 1999. He is Python trainer and CEO at Python Academy (python-academy.com). He teaches a wide variety of Python topics including introductory, scientific, and advanced as well as optimization topics. He taught 400+ trainings, totaling 1.000+ full training days. He has been chairman of the Python Software Verband since 2012. Furthermore, he is a PSF fellow, a PSF community service award holder, and User Group co-founder. He chaired the first two EuroSciPy conferences 2008/2009, as well as PyConDE2011/2012 and EuroPython2014. He has been an active organizer of all PyConDE and EuroSciPy conferences.",
            "Title": "Migration from Python 2 to 3",
            "Description": "Python 2 reached end of life (EOL). However, there are still many projects that\nuse Python 2. Staying with Python 2 is certainly no long-term option for most\nprojects.\nPorting a larger program to Python 3 brakes backward compatibility with \nPython 2. One solution for this problem is the single-source approach that\nresults in source code that runs with Python 2 and 3 without any changes.\nThis tutorial provides a short overview over the most important differences\nbetween Python 2 and 3. After looking at different approaches for Python 3\nsupport, the focus will be on writing single-source programs with \npython-future. You will learn how to port to Python 3 without loosing Python 2\nsupport. Finally dropping Python 2 support will get as simple as removing a few\nimports.\nThe content of this tutorial is inspired by questions I received from \nparticipants in trainings about how to smoothly transition from Python 2 to \nPython 3. Making Python 2 working as much as possible as Python 3 seems the best\noption to me. You are encouraged to bring your questions about this topic.\nI teach about this topic on a regular basis in my trainings. Being a full-time\nprofession trainer, I have plenty opportunity to get involved with many \nprogrammers who have to deal with this problem.\nYou will need Python 3.8 installed on your laptop. Python 3.6/3.7 should also \nwork. You also need Python 2.7 installed to test if the code runs with Python 2 \nand Python 3. You may use Python 3.9 if is released at the time of the tutorial\nand all dependencies can be installed.\nI will use a JupyterLab for the tutorial because it makes a very good\nteaching tool. You are welcome to use the setup you prefer, i.e editor, IDE,\nREPL. If you also like to use a JupyterLab, I recommend conda for\neasy installation. Similarly to virtualenv, conda allows creating isolated\nenvironments but allows binary installs for all platforms.\nThere are two ways to install Jupyter via conda:\nYou can create a comparable setup with virtual environments and pip, if you\nprefer.\nAfter creating a new environment, the system might still work with some\nstale settings. Even when the command which tells you that you are using an\nexecutable from your environment, this might actually not be the case.\nIf you see strange behavior using a command line tool in your environment,\nuse hash -r and try again.",
            "Video_link": "https://youtu.be/JgIgEjASOlk",
            "Video_id": "JgIgEjASOlk",
            "viewCount": 109,
            "likeCount": 2,
            "dislikeCount": 0,
            "favoriteCount": 0,
            "commentCount": 0
        },
        {
            "Author": "Geir Arne Hjelle",
            "Bio": "Geir Arne writes and reviews articles at Real Python, although his main gig is a a data scientist at Nextbridge Analytics in Oslo, Norway.  He has broad experience ranging from theoretical mathematics research, via electricity market modeling to high precision positioning using satellite systems like GPS. After playing with everything from Basic, Awk, Java, and C to Assembly, he now does most of his coding in Python. Other favorites include board games, hammocks, square roots and skiing (preferably up-hill). In his spare time, he also gets to teach kids how to code.",
            "Title": "Introduction to Decorators: Power Up Your Python Code",
            "Description": "Python supports functions as first-class objects. This means that functions can be assigned to variables, and passed to and from other functions, just like any other object in Python.\nOne powerful application of this is the decorator syntax, which makes it easy to apply one function to another at compile time. Decorators offer a simple and readable way of adding capabilities to your code. This tutorial will teach you how decorators work, and how to create your own decorators. \nBeing comfortable with using and creating decorators, will make you a more efficient Python programmer. You will learn how a single line sometimes can transform your code: add authentication to your website, write a class for you, or even JIT-compile your long-running calculations.",
            "Video_link": "https://youtu.be/T8CQwGIsrx4",
            "Video_id": "T8CQwGIsrx4",
            "viewCount": 264,
            "likeCount": 9,
            "dislikeCount": 1,
            "favoriteCount": 0,
            "commentCount": 0
        }
    ]
}